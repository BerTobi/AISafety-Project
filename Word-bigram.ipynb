{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa89129-a0a8-4217-bdd8-68ebc583c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "71dfad9f-96be-464f-a842-936a4b65c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1896"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('Dataset/Test Español/Test.txt', 'r').read().split()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fc29717-8dea-4b38-bdcf-f7205edd7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 924\n"
     ]
    }
   ],
   "source": [
    "uwords = set(words)\n",
    "print(f'Vocabulary size: {len(uwords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93c27e0e-2e82-40fd-ae07-10af26333686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(uwords) > 1000:\n",
    "    print(\"Very large vocabulary detected. Consider limiting vocabulary size.\")\n",
    "    from collections import Counter\n",
    "    word_counts = Counter(words)\n",
    "    top_words = [word for word, _ in word_counts.most_common(1000)]\n",
    "    uwords = set(top_words)\n",
    "    print(f'Limited vocabulary to top 1000 words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7bda0541-b3ee-40e3-9335-7b21df9429df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtoi = {s:i for i,s in enumerate(uwords)}\n",
    "itow = {i:s for s,i in wtoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffd773de-ea79-4d93-a145-3add5ebc2ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  1895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1895"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w1, w2 in zip(words, words[1:]):\n",
    "    if w1 in uwords and w2 in uwords:\n",
    "        ix1 = wtoi[w1]\n",
    "        ix2 = wtoi[w2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "len(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a6e1fea-7657-4e64-9d29-eb4e066e40a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cpu\" not implemented for 'Bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# initialize the 'network'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m g \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mGenerator()\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m10022004\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m W\u001b[38;5;241m.\u001b[39mdtype\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"normal_kernel_cpu\" not implemented for 'Bool'"
     ]
    }
   ],
   "source": [
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(10022004)\n",
    "W = torch.randn((len(uwords), len(uwords)), generator=g, requires_grad=True, dtype=torch.float16)\n",
    "W.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01f7bae9-597a-47f0-9171-c309b08a97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  0 loss:  7.32421875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m logits \u001b[38;5;241m=\u001b[39m xenc \u001b[38;5;241m@\u001b[39m W \u001b[38;5;66;03m# predict log-counts\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#counts = logits.exp() # counts, equivalent to N\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#loss = -probs[torch.arange(num), ys].log().mean()\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (k \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;124m\"\u001b[39m, k, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3389\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3384\u001b[0m         reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   3386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduced\n\u001b[1;32m-> 3389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_entropy\u001b[39m(\n\u001b[0;32m   3390\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m   3391\u001b[0m     target: Tensor,\n\u001b[0;32m   3392\u001b[0m     weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3393\u001b[0m     size_average: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3394\u001b[0m     ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   3395\u001b[0m     reduce: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3396\u001b[0m     reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3397\u001b[0m     label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m   3398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m   3399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the cross entropy loss between input logits and target.\u001b[39;00m\n\u001b[0;32m   3400\u001b[0m \n\u001b[0;32m   3401\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.CrossEntropyLoss` for details.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;124;03m        >>> loss.backward()\u001b[39;00m\n\u001b[0;32m   3463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=len(uwords)).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    #counts = logits.exp() # counts, equivalent to N\n",
    "    #probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    #loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    loss = torch.nn.functional.cross_entropy(logits, ys)\n",
    "    if (k % 100 == 0):\n",
    "        print(\"step: \", k, \"loss: \", loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    with torch.no_grad():\n",
    "        W -= 50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abf63331-5f6f-4e7f-a2ca-c66d04c8bd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7056,  0.8052, -0.0105,  ..., -1.1589,  2.0847, -0.7403],\n",
       "        [-0.0558,  0.1391, -0.5751,  ..., -0.2039,  0.7923,  0.6101],\n",
       "        [-0.4650, -0.6915,  1.6357,  ..., -0.8117,  0.7727, -0.5670],\n",
       "        ...,\n",
       "        [-0.5403,  0.5932,  0.1426,  ..., -0.1567,  1.2153, -1.5757],\n",
       "        [ 1.5530, -0.1820, -0.9679,  ...,  1.8583,  0.1253, -1.3439],\n",
       "        [ 0.4030,  0.4487, -1.2789,  ...,  0.0491,  2.2162,  1.2107]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "685313b8-27bc-4ac0-ba23-91f82f0eb2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " movía más. *Dripp* Algo cayó desde que ganar dinero fueron completamente negra, hubiera roto. Hay muchas personas moverse objeto adornada\n",
      " no está funcionando bien porque se hubiera nacido en varios aspectos. Si el juego. Entre los Rol mientras cumplieras es\n",
      " brilló en el oponente fuese collar jugadores. Las razas llegaría a sus DMMO-RPGs que DMMO-RPG no podía pedirle perdón por\n",
      " no estaba aferrándose a su alma mundos existencia que podía alegrarse porque se congeló en el hogar del jugador. Me\n",
      " no se sentaron. Uno llevaba una existencia que no que destacaba Era el último día que se ovación que lo\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    out = \"\"\n",
    "    ix = 0\n",
    "    for j in range(20):\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=len(uwords)).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next word\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out += \" \" + itow[ix]\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94488307-825e-4877-9fdc-413ce7189cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "78c77ce2-9142-44b1-828e-44a237e0a546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 text files in Dataset/English\n",
      "Processing file: Dataset/English\\Birds.txt\n",
      "Processing file: Dataset/English\\Encyclopedia.txt\n",
      "Processing file: Dataset/English\\House rats and mice.txt\n",
      "Processing file: Dataset/English\\Leviathan.txt\n",
      "Total words read: 1589302\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "folder_path = 'Dataset/English'  # Change this to your folder path\n",
    "\n",
    "# Get all text files in the folder\n",
    "file_paths = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "print(f'Found {len(file_paths)} text files in {folder_path}')\n",
    "\n",
    "# Read and combine all words from all files\n",
    "all_words = []\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        print(f'Processing file: {file_path}')\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            words = file.read().split()\n",
    "            all_words.extend(words)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {file_path}: {str(e)}')\n",
    "\n",
    "print(f'Total words read: {len(all_words)}')\n",
    "\n",
    "words = all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "00a94426-6805-4dc5-b6ac-a11c8f8692df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very large vocabulary detected: 154827 words. Consider limiting vocabulary size.\n",
      "Limited vocabulary to top 2000 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uwords = set(all_words)\n",
    "size = len(uwords)\n",
    "\n",
    "vocab_limit = 2000\n",
    "\n",
    "if len(uwords) > vocab_limit:\n",
    "    print(f\"Very large vocabulary detected: {size} words. Consider limiting vocabulary size.\")\n",
    "    from collections import Counter\n",
    "    word_counts = Counter(words)\n",
    "    top_words = [word for word, _ in word_counts.most_common(vocab_limit)]\n",
    "    uwords = set(top_words)\n",
    "    print(f'Limited vocabulary to top {vocab_limit} words')\n",
    "\n",
    "wtoi = {s:i for i,s in enumerate(uwords)}\n",
    "itow = {i:s for s,i in wtoi.items()}\n",
    "\n",
    "size = len(uwords)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3cdc1e0b-dbdb-4762-b7b0-56a446a9b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros(size, size, dtype = torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "772314d9-1973-4b68-a234-a6bf4a697a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 bigrams\n",
      "There are 20000 bigrams\n",
      "There are 30000 bigrams\n",
      "There are 40000 bigrams\n",
      "There are 50000 bigrams\n",
      "There are 60000 bigrams\n",
      "There are 70000 bigrams\n",
      "There are 80000 bigrams\n",
      "There are 90000 bigrams\n",
      "There are 100000 bigrams\n",
      "There are 110000 bigrams\n",
      "There are 120000 bigrams\n",
      "There are 130000 bigrams\n",
      "There are 140000 bigrams\n",
      "There are 150000 bigrams\n",
      "There are 160000 bigrams\n",
      "There are 170000 bigrams\n",
      "There are 180000 bigrams\n",
      "There are 190000 bigrams\n",
      "There are 200000 bigrams\n",
      "There are 210000 bigrams\n",
      "There are 220000 bigrams\n",
      "There are 230000 bigrams\n",
      "There are 240000 bigrams\n",
      "There are 250000 bigrams\n",
      "There are 260000 bigrams\n",
      "There are 270000 bigrams\n",
      "There are 280000 bigrams\n",
      "There are 290000 bigrams\n",
      "There are 300000 bigrams\n",
      "There are 310000 bigrams\n",
      "There are 320000 bigrams\n",
      "There are 330000 bigrams\n",
      "There are 340000 bigrams\n",
      "There are 350000 bigrams\n",
      "There are 360000 bigrams\n",
      "There are 370000 bigrams\n",
      "There are 380000 bigrams\n",
      "There are 390000 bigrams\n",
      "There are 400000 bigrams\n",
      "There are 410000 bigrams\n",
      "There are 420000 bigrams\n",
      "There are 430000 bigrams\n",
      "There are 440000 bigrams\n",
      "There are 450000 bigrams\n",
      "There are 460000 bigrams\n",
      "There are 470000 bigrams\n",
      "There are 480000 bigrams\n",
      "There are 490000 bigrams\n",
      "There are 500000 bigrams\n",
      "There are 510000 bigrams\n",
      "There are 520000 bigrams\n",
      "There are 530000 bigrams\n",
      "There are 540000 bigrams\n",
      "There are 550000 bigrams\n",
      "There are 560000 bigrams\n",
      "There are 570000 bigrams\n",
      "There are 580000 bigrams\n"
     ]
    }
   ],
   "source": [
    "# getting the Bigrams\n",
    "bigrams = 0\n",
    "b = {}\n",
    "for w1, w2 in zip(words, words[1:]):\n",
    "    if w1 in uwords and w2 in uwords:\n",
    "        ix1 = wtoi[w1]\n",
    "        ix2 = wtoi[w2]\n",
    "\n",
    "        if (N[ix1, ix2].item() < 255):\n",
    "            N[ix1, ix2] += 1\n",
    "            bigrams += 1\n",
    "            if (bigrams % 10000 == 0):\n",
    "                print(f\"There are {bigrams} bigrams\")\n",
    "            bigram = (w1, w2)\n",
    "            b[bigram] = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7c4c51ae-46bc-465f-bd48-3da56bd04c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('in', 'the'), 255),\n",
       " (('have', 'been'), 255),\n",
       " (('for', 'a'), 255),\n",
       " (('of', 'the'), 255),\n",
       " (('the', 'first'), 255),\n",
       " (('as', 'a'), 255),\n",
       " (('It', 'is'), 255),\n",
       " (('one', 'of'), 255),\n",
       " (('the', 'most'), 255),\n",
       " (('in', 'this'), 255),\n",
       " (('and', 'it'), 255),\n",
       " (('on', 'the'), 255),\n",
       " (('to', 'the'), 255),\n",
       " (('by', 'the'), 255),\n",
       " (('the', 'United'), 255),\n",
       " (('of', 'a'), 255),\n",
       " (('among', 'the'), 255),\n",
       " (('a', 'few'), 255),\n",
       " (('with', 'the'), 255),\n",
       " (('is', 'the'), 255),\n",
       " (('and', 'other'), 255),\n",
       " (('that', 'is'), 255),\n",
       " (('but', 'in'), 255),\n",
       " (('with', 'a'), 255),\n",
       " (('are', 'the'), 255),\n",
       " (('form', 'of'), 255),\n",
       " (('of', 'these'), 255),\n",
       " (('can', 'be'), 255),\n",
       " (('means', 'of'), 255),\n",
       " (('in', 'a'), 255),\n",
       " (('from', 'the'), 255),\n",
       " (('number', 'of'), 255),\n",
       " (('that', 'the'), 255),\n",
       " (('to', 'be'), 255),\n",
       " (('known', 'as'), 255),\n",
       " (('it', 'is'), 255),\n",
       " (('and', 'in'), 255),\n",
       " (('is', 'a'), 255),\n",
       " (('of', 'an'), 255),\n",
       " (('for', 'the'), 255),\n",
       " (('in', 'their'), 255),\n",
       " (('is', 'not'), 255),\n",
       " (('in', 'which'), 255),\n",
       " (('which', 'they'), 255),\n",
       " (('some', 'of'), 255),\n",
       " (('as', 'it'), 255),\n",
       " (('the', 'time'), 255),\n",
       " (('time', 'of'), 255),\n",
       " (('in', 'all'), 255),\n",
       " (('and', 'the'), 255),\n",
       " (('not', 'to'), 255),\n",
       " (('upon', 'the'), 255),\n",
       " (('as', 'the'), 255),\n",
       " (('when', 'the'), 255),\n",
       " (('through', 'the'), 255),\n",
       " (('of', 'his'), 255),\n",
       " (('by', 'his'), 255),\n",
       " (('he', 'is'), 255),\n",
       " (('the', 'same'), 255),\n",
       " (('and', 'to'), 255),\n",
       " (('of', 'this'), 255),\n",
       " (('as', 'well'), 255),\n",
       " (('well', 'as'), 255),\n",
       " (('they', 'are'), 255),\n",
       " (('at', 'the'), 255),\n",
       " (('under', 'the'), 255),\n",
       " (('or', 'the'), 255),\n",
       " (('did', 'not'), 255),\n",
       " (('all', 'the'), 255),\n",
       " (('use', 'of'), 255),\n",
       " (('and', 'their'), 255),\n",
       " (('by', 'a'), 255),\n",
       " (('but', 'the'), 255),\n",
       " (('has', 'been'), 255),\n",
       " (('that', 'of'), 255),\n",
       " (('of', 'all'), 255),\n",
       " (('may', 'be'), 255),\n",
       " (('and', 'at'), 255),\n",
       " (('over', 'the'), 255),\n",
       " (('which', 'he'), 255),\n",
       " (('parts', 'of'), 255),\n",
       " (('In', 'the'), 255),\n",
       " (('those', 'of'), 255),\n",
       " (('and', 'he'), 255),\n",
       " (('of', 'its'), 255),\n",
       " (('as', 'to'), 255),\n",
       " (('and', 'by'), 255),\n",
       " (('during', 'the'), 255),\n",
       " (('found', 'in'), 255),\n",
       " (('while', 'the'), 255),\n",
       " (('the', 'other'), 255),\n",
       " (('to', 'make'), 255),\n",
       " (('to', 'have'), 255),\n",
       " (('that', 'he'), 255),\n",
       " (('has', 'a'), 255),\n",
       " (('and', 'is'), 255),\n",
       " (('according', 'to'), 255),\n",
       " (('in', 'his'), 255),\n",
       " (('to', 'his'), 255),\n",
       " (('there', 'is'), 255),\n",
       " (('of', 'any'), 255),\n",
       " (('from', 'a'), 255),\n",
       " (('part', 'of'), 255),\n",
       " (('the', 'great'), 255),\n",
       " (('the', 'latter'), 255),\n",
       " (('and', 'on'), 255),\n",
       " (('is', 'an'), 255),\n",
       " (('and', 'a'), 255),\n",
       " (('is', 'also'), 255),\n",
       " (('of', 'them'), 255),\n",
       " (('of', 'that'), 255),\n",
       " (('and', 'its'), 255),\n",
       " (('is', 'no'), 255),\n",
       " (('him', 'to'), 255),\n",
       " (('of', 'which'), 255),\n",
       " (('which', 'are'), 255),\n",
       " (('to', 'a'), 255),\n",
       " (('they', 'were'), 255),\n",
       " (('before', 'the'), 255),\n",
       " (('are', 'not'), 255),\n",
       " (('as', 'in'), 255),\n",
       " (('was', 'made'), 255),\n",
       " (('there', 'are'), 255),\n",
       " (('which', 'it'), 255),\n",
       " (('where', 'the'), 255),\n",
       " (('which', 'the'), 255),\n",
       " (('it', 'was'), 255),\n",
       " (('had', 'been'), 255),\n",
       " (('and', 'that'), 255),\n",
       " (('is', 'that'), 255),\n",
       " (('such', 'as'), 255),\n",
       " (('of', 'their'), 255),\n",
       " (('than', 'the'), 255),\n",
       " (('more', 'than'), 255),\n",
       " (('against', 'the'), 255),\n",
       " (('in', 'its'), 255),\n",
       " (('a', 'large'), 255),\n",
       " (('as', 'an'), 255),\n",
       " (('United', 'States'), 255),\n",
       " (('the', 'end'), 255),\n",
       " (('end', 'of'), 255),\n",
       " (('On', 'the'), 255),\n",
       " (('to', 'which'), 255),\n",
       " (('is', 'to'), 255),\n",
       " (('the', 'French'), 255),\n",
       " (('said', 'to'), 255),\n",
       " (('that', 'they'), 255),\n",
       " (('should', 'be'), 255),\n",
       " (('out', 'of'), 255),\n",
       " (('at', 'a'), 255),\n",
       " (('into', 'a'), 255),\n",
       " (('which', 'is'), 255),\n",
       " (('that', 'it'), 255),\n",
       " (('the', 'case'), 255),\n",
       " (('and', 'his'), 255),\n",
       " (('is', 'in'), 255),\n",
       " (('It', 'was'), 255),\n",
       " (('on', 'a'), 255),\n",
       " (('was', 'the'), 255),\n",
       " (('a', 'great'), 255),\n",
       " (('was', 'not'), 255),\n",
       " (('name', 'of'), 255),\n",
       " (('was', 'a'), 255),\n",
       " (('history', 'of'), 255),\n",
       " (('the', 'chief'), 255),\n",
       " (('into', 'the'), 255),\n",
       " (('the', 'two'), 255),\n",
       " (('after', 'the'), 255),\n",
       " (('the', 'name'), 255),\n",
       " (('he', 'was'), 255),\n",
       " (('account', 'of'), 255),\n",
       " (('the', 'whole'), 255),\n",
       " (('the', 'British'), 255),\n",
       " (('was', 'born'), 255),\n",
       " (('born', 'at'), 255),\n",
       " (('son', 'of'), 255),\n",
       " (('in', 'that'), 255),\n",
       " (('case', 'of'), 255),\n",
       " (('which', 'was'), 255),\n",
       " (('the', 'second'), 255),\n",
       " (('He', 'was'), 255),\n",
       " (('he', 'had'), 255),\n",
       " (('and', 'of'), 255),\n",
       " (('and', 'was'), 255),\n",
       " (('by', 'which'), 255),\n",
       " (('must', 'be'), 255),\n",
       " (('where', 'he'), 255),\n",
       " (('of', 'St'), 255),\n",
       " (('a', 'man'), 255),\n",
       " (('king', 'of'), 255),\n",
       " (('his', 'own'), 255),\n",
       " (('between', 'the'), 255),\n",
       " (('was', 'to'), 255),\n",
       " (('.', '.'), 255),\n",
       " (('to', 'say,'), 255),\n",
       " (('it', 'has'), 252),\n",
       " (('that', 'in'), 250),\n",
       " (('for', 'his'), 250),\n",
       " (('the', 'following'), 250),\n",
       " (('the', 'last'), 250),\n",
       " (('and', 'for'), 247),\n",
       " (('their', 'own'), 243),\n",
       " (('who', 'had'), 243),\n",
       " (('but', 'it'), 242),\n",
       " (('At', 'the'), 242),\n",
       " (('so', 'that'), 241),\n",
       " (('the', 'middle'), 240),\n",
       " (('due', 'to'), 240),\n",
       " (('was', 'in'), 240),\n",
       " (('that', 'is,'), 240),\n",
       " (('and', 'are'), 239),\n",
       " (('does', 'not'), 237),\n",
       " (('But', 'the'), 236),\n",
       " (('There', 'are'), 236),\n",
       " (('is', 'said'), 236),\n",
       " (('a', 'small'), 235),\n",
       " (('will', 'be'), 233),\n",
       " (('that', 'which'), 233),\n",
       " (('the', 'river'), 232),\n",
       " (('when', 'he'), 231),\n",
       " (('the', 'north'), 231),\n",
       " (('the', 'best'), 230),\n",
       " (('would', 'be'), 229),\n",
       " (('the', 'Roman'), 229),\n",
       " (('There', 'is'), 228),\n",
       " (('a', 'very'), 228),\n",
       " (('on', 'his'), 228),\n",
       " (('is', 'now'), 228),\n",
       " (('far', 'as'), 227),\n",
       " (('For', 'the'), 226),\n",
       " (('The', 'first'), 224),\n",
       " (('to', 'take'), 222),\n",
       " (('the', 'state'), 222),\n",
       " (('the', 'country'), 221),\n",
       " (('near', 'the'), 221),\n",
       " (('the', 'more'), 220),\n",
       " (('with', 'his'), 220),\n",
       " (('the', 'south'), 220),\n",
       " (('of', 'one'), 218),\n",
       " (('about', 'the'), 217),\n",
       " (('the', 'use'), 216),\n",
       " (('the', 'right'), 216),\n",
       " (('to', 'their'), 215),\n",
       " (('be', 'the'), 215),\n",
       " (('which', 'had'), 214),\n",
       " (('the', 'old'), 214),\n",
       " (('not', 'only'), 212),\n",
       " (('the', 'general'), 212),\n",
       " (('death', 'of'), 212),\n",
       " (('the', 'English'), 211),\n",
       " (('of', 'those'), 211),\n",
       " (('the', 'city'), 211),\n",
       " (('of', 'some'), 209),\n",
       " (('and', 'not'), 208),\n",
       " (('if', 'the'), 207),\n",
       " (('is', 'of'), 206),\n",
       " (('as', 'they'), 205),\n",
       " (('seems', 'to'), 205),\n",
       " (('series', 'of'), 205),\n",
       " (('given', 'to'), 205),\n",
       " (('to', 'that'), 205),\n",
       " (('a', 'new'), 204),\n",
       " (('used', 'in'), 204),\n",
       " (('knowledge', 'of'), 204),\n",
       " (('any', 'other'), 203),\n",
       " (('this', 'is'), 203),\n",
       " (('up', 'to'), 203),\n",
       " (('work', 'of'), 202),\n",
       " (('side', 'of'), 202),\n",
       " (('called', 'the'), 202),\n",
       " (('the', 'word'), 202),\n",
       " (('de', 'la'), 202),\n",
       " (('above', 'the'), 201),\n",
       " (('portion', 'of'), 201),\n",
       " (('cannot', 'be'), 201),\n",
       " (('and', 'an'), 201),\n",
       " (('or', 'by'), 201),\n",
       " (('who', 'was'), 201),\n",
       " (('the', 'work'), 201),\n",
       " (('be', 'a'), 200),\n",
       " (('that', 'a'), 200),\n",
       " (('town', 'of'), 200),\n",
       " (('the', 'present'), 200),\n",
       " (('also', 'the'), 200),\n",
       " (('the', 'northern'), 199),\n",
       " (('the', 'town'), 199),\n",
       " (('in', 'some'), 199),\n",
       " (('shall', 'be'), 198),\n",
       " (('there', 'was'), 198),\n",
       " (('Great', 'Britain'), 198),\n",
       " (('and', 'from'), 197),\n",
       " (('which', 'were'), 197),\n",
       " (('to', 'give'), 197),\n",
       " (('it', 'to'), 197),\n",
       " (('It', 'has'), 196),\n",
       " (('They', 'are'), 196),\n",
       " (('derived', 'from'), 196),\n",
       " (('and', 'then'), 196),\n",
       " (('state', 'of'), 196),\n",
       " (('to', 'its'), 195),\n",
       " (('such', 'a'), 195),\n",
       " (('the', 'place'), 195),\n",
       " (('not', 'the'), 194),\n",
       " (('the', 'lower'), 193),\n",
       " (('the', 'death'), 193),\n",
       " (('within', 'the'), 192),\n",
       " (('in', 'an'), 192),\n",
       " (('the', 'Greek'), 192),\n",
       " (('to', 'this'), 191),\n",
       " (('and', 'so'), 190),\n",
       " (('the', 'upper'), 189),\n",
       " (('but', 'a'), 189),\n",
       " (('regarded', 'as'), 189),\n",
       " (('a', 'number'), 189),\n",
       " (('in', 'any'), 188),\n",
       " (('the', 'only'), 188),\n",
       " (('is', 'called'), 188),\n",
       " (('and', 'there'), 188),\n",
       " (('they', 'have'), 188),\n",
       " (('History', 'of'), 188),\n",
       " (('which', 'has'), 187),\n",
       " (('the', 'west'), 187),\n",
       " (('not', 'be'), 186),\n",
       " (('or', 'other'), 186),\n",
       " (('by', 'an'), 186),\n",
       " (('and', 'as'), 185),\n",
       " (('are', 'to'), 185),\n",
       " (('the', 'emperor'), 185),\n",
       " (('the', 'main'), 184),\n",
       " (('when', 'they'), 183),\n",
       " (('and', 'also'), 183),\n",
       " (('He', 'died'), 183),\n",
       " (('duke', 'of'), 183),\n",
       " (('course', 'of'), 182),\n",
       " (('were', 'the'), 182),\n",
       " (('along', 'the'), 180),\n",
       " (('the', 'eastern'), 180),\n",
       " (('of', 'our'), 179),\n",
       " (('the', 'southern'), 179),\n",
       " (('towards', 'the'), 179),\n",
       " (('the', 'early'), 178),\n",
       " (('for', 'their'), 178),\n",
       " (('nature', 'of'), 178),\n",
       " (('the', 'title'), 178),\n",
       " (('many', 'of'), 177),\n",
       " (('the', 'fact'), 177),\n",
       " (('do', 'not'), 177),\n",
       " (('were', 'not'), 176),\n",
       " (('be', 'made'), 176),\n",
       " (('subject', 'to'), 176),\n",
       " (('the', 'former'), 176),\n",
       " (('be', 'found'), 175),\n",
       " (('order', 'to'), 175),\n",
       " (('a', 'certain'), 175),\n",
       " (('are', 'in'), 174),\n",
       " (('the', 'king'), 174),\n",
       " (('of', 'such'), 174),\n",
       " (('the', 'principal'), 174),\n",
       " (('the', 'people'), 174),\n",
       " (('owing', 'to'), 174),\n",
       " (('and', 'therefore'), 174),\n",
       " (('the', 'Soveraign'), 174),\n",
       " (('the', 'new'), 173),\n",
       " (('most', 'important'), 173),\n",
       " (('the', 'year'), 172),\n",
       " (('power', 'of'), 172),\n",
       " (('but', 'he'), 171),\n",
       " (('published', 'in'), 171),\n",
       " (('by', 'means'), 171),\n",
       " (('action', 'of'), 171),\n",
       " (('north', 'of'), 170),\n",
       " (('had', 'a'), 170),\n",
       " (('fact', 'that'), 169),\n",
       " (('in', 'order'), 169),\n",
       " (('was', 'appointed'), 169),\n",
       " (('the', 'Law'), 169),\n",
       " (('to', 'an'), 169),\n",
       " (('of', 'two'), 169),\n",
       " (('part', 'in'), 168),\n",
       " (('province', 'of'), 168),\n",
       " (('system', 'of'), 168),\n",
       " (('from', 'which'), 167),\n",
       " (('the', 'form'), 167),\n",
       " (('act', 'of'), 167),\n",
       " (('led', 'to'), 167),\n",
       " (('by', 'their'), 167),\n",
       " (('most', 'of'), 166),\n",
       " (('of', 'God,'), 166),\n",
       " (('as', 'he'), 165),\n",
       " (('from', 'his'), 164),\n",
       " (('being', 'the'), 164),\n",
       " (('and', 'with'), 164),\n",
       " (('to', 'him'), 164),\n",
       " (('and', 'after'), 164),\n",
       " (('the', 'number'), 164),\n",
       " (('is', 'very'), 163),\n",
       " (('the', '19th'), 163),\n",
       " (('place', 'of'), 162),\n",
       " (('the', 'western'), 161),\n",
       " (('the', 'head'), 161),\n",
       " (('or', 'a'), 160),\n",
       " (('or', 'in'), 160),\n",
       " (('could', 'not'), 160),\n",
       " (('as', 'far'), 160),\n",
       " (('made', 'to'), 160),\n",
       " (('value', 'of'), 160),\n",
       " (('the', 'history'), 160),\n",
       " (('the', 'east'), 160),\n",
       " (('though', 'the'), 160),\n",
       " (('In', 'this'), 160),\n",
       " (('we', 'have'), 159),\n",
       " (('Project', 'Gutenberg™'), 159),\n",
       " (('are', 'of'), 158),\n",
       " (('a', 'considerable'), 158),\n",
       " (('or', 'of'), 158),\n",
       " (('the', 'Royal'), 157),\n",
       " (('amount', 'of'), 157),\n",
       " (('appears', 'to'), 157),\n",
       " (('are', 'also'), 157),\n",
       " (('the', 'coast'), 156),\n",
       " (('of', 'it'), 155),\n",
       " (('with', 'an'), 155),\n",
       " (('south', 'of'), 155),\n",
       " (('he', 'that'), 155),\n",
       " (('consists', 'of'), 154),\n",
       " (('member', 'of'), 154),\n",
       " (('at', 'least'), 154),\n",
       " (('in', 'such'), 153),\n",
       " (('head', 'of'), 153),\n",
       " (('the', 'ancient'), 153),\n",
       " (('of', 'great'), 153),\n",
       " (('years', 'of'), 152),\n",
       " (('point', 'of'), 152),\n",
       " (('the', 'common'), 151),\n",
       " (('beginning', 'of'), 151),\n",
       " (('the', 'American'), 151),\n",
       " (('title', 'of'), 151),\n",
       " (('but', 'also'), 151),\n",
       " (('is', 'one'), 150),\n",
       " (('them', 'to'), 150),\n",
       " (('the', 'beginning'), 150),\n",
       " (('it', 'may'), 150),\n",
       " (('after', 'a'), 149),\n",
       " (('it', 'be'), 149),\n",
       " (('the', '18th'), 149),\n",
       " (('the', 'action'), 149),\n",
       " (('when', 'it'), 148),\n",
       " (('what', 'is'), 148),\n",
       " (('made', 'by'), 148),\n",
       " (('up', 'the'), 148),\n",
       " (('I', 'have'), 148),\n",
       " (('began', 'to'), 148),\n",
       " (('that', 'are'), 148),\n",
       " (('the', 'nature'), 148),\n",
       " (('it', 'in'), 147),\n",
       " (('Of', 'the'), 147),\n",
       " (('to', 'any'), 146),\n",
       " (('for', 'some'), 146),\n",
       " (('to', 'whom'), 146),\n",
       " (('and', 'this'), 145),\n",
       " (('coast', 'of'), 145),\n",
       " (('that', 'there'), 145),\n",
       " (('Law', 'of'), 145),\n",
       " (('if', 'he'), 144),\n",
       " (('so', 'far'), 144),\n",
       " (('whom', 'he'), 144),\n",
       " (('connected', 'with'), 143),\n",
       " (('the', 'German'), 142),\n",
       " (('for', 'its'), 142),\n",
       " (('From', 'the'), 141),\n",
       " (('a', 'good'), 141),\n",
       " (('in', 'one'), 141),\n",
       " (('and', 'has'), 141),\n",
       " (('less', 'than'), 141),\n",
       " (('he', 'became'), 141),\n",
       " (('died', 'in'), 141),\n",
       " (('the', 'power'), 141),\n",
       " (('This', 'is'), 140),\n",
       " (('made', 'in'), 140),\n",
       " (('condition', 'of'), 140),\n",
       " (('until', 'the'), 140),\n",
       " (('for', 'which'), 140),\n",
       " (('is', 'found'), 139),\n",
       " (('and', 'more'), 139),\n",
       " (('the', 'original'), 139),\n",
       " (('works', 'of'), 139),\n",
       " (('to', 'all'), 139),\n",
       " (('there', 'were'), 139),\n",
       " (('or', 'to'), 138),\n",
       " (('the', 'greater'), 138),\n",
       " (('in', 'many'), 138),\n",
       " (('the', '16th'), 138),\n",
       " (('regard', 'to'), 138),\n",
       " (('and', 'all'), 137),\n",
       " (('According', 'to'), 137),\n",
       " (('the', 'various'), 137),\n",
       " (('have', 'the'), 137),\n",
       " (('to', 'those'), 137),\n",
       " (('the', 'subject'), 137),\n",
       " (('was', 'an'), 137),\n",
       " (('same', 'time'), 137),\n",
       " (('having', 'been'), 136),\n",
       " (('they', 'had'), 136),\n",
       " (('the', 'third'), 136),\n",
       " (('but', 'to'), 135),\n",
       " (('made', 'of'), 135),\n",
       " (('a', 'town'), 135),\n",
       " (('died', 'at'), 135),\n",
       " (('study', 'of'), 135),\n",
       " (('of', 'God'), 135),\n",
       " (('that', 'have'), 135),\n",
       " (('and', 'some'), 134),\n",
       " (('seem', 'to'), 134),\n",
       " (('presence', 'of'), 134),\n",
       " (('was', 'also'), 134),\n",
       " (('Kingdome', 'of'), 134),\n",
       " (('kind', 'of'), 133),\n",
       " (('used', 'for'), 133),\n",
       " (('known', 'to'), 133),\n",
       " (('with', 'which'), 133),\n",
       " (('the', 'term'), 133),\n",
       " (('him', 'in'), 133),\n",
       " (('the', 'land'), 132),\n",
       " (('could', 'be'), 132),\n",
       " (('centre', 'of'), 132),\n",
       " (('of', 'her'), 132),\n",
       " (('the', 'Civill'), 132),\n",
       " (('till', 'the'), 131),\n",
       " (('had', 'to'), 131),\n",
       " (('the', 'province'), 131),\n",
       " (('members', 'of'), 131),\n",
       " (('there', 'be'), 130),\n",
       " (('period', 'of'), 130),\n",
       " (('might', 'be'), 130),\n",
       " (('returned', 'to'), 130),\n",
       " (('the', 'war'), 130),\n",
       " (('became', 'a'), 130),\n",
       " (('area', 'of'), 130),\n",
       " (('connexion', 'with'), 130),\n",
       " (('have', 'a'), 129),\n",
       " (('possession', 'of'), 129),\n",
       " (('During', 'the'), 129),\n",
       " (('the', 'church'), 129),\n",
       " (('time', 'to'), 129),\n",
       " (('those', 'that'), 129),\n",
       " (('the', 'highest'), 128),\n",
       " (('line', 'of'), 128),\n",
       " (('development', 'of'), 128),\n",
       " (('made', 'a'), 128),\n",
       " (('if', 'it'), 128),\n",
       " (('is', 'known'), 128),\n",
       " (('not', 'a'), 127),\n",
       " (('at', 'once'), 127),\n",
       " (('the', 'son'), 127),\n",
       " (('the', 'author'), 127),\n",
       " (('is', 'still'), 127),\n",
       " (('them', 'that'), 127),\n",
       " (('able', 'to'), 126),\n",
       " (('middle', 'of'), 126),\n",
       " (('a', 'long'), 126),\n",
       " (('the', 'next'), 126),\n",
       " (('in', 'England'), 126),\n",
       " (('which', 'a'), 126),\n",
       " (('a', 'single'), 125),\n",
       " (('and', 'when'), 125),\n",
       " (('the', 'New'), 125),\n",
       " (('a', 'more'), 125),\n",
       " (('the', 'centre'), 125),\n",
       " (('court', 'of'), 125),\n",
       " (('of', 'August'), 125),\n",
       " (('the', 'government'), 125),\n",
       " (('the', 'Holy'), 125),\n",
       " (('died', 'on'), 125),\n",
       " (('which', 'have'), 125),\n",
       " (('other', 'hand,'), 124),\n",
       " (('to', 'form'), 124),\n",
       " (('the', 'court'), 124),\n",
       " (('of', 'about'), 124),\n",
       " (('influence', 'of'), 124),\n",
       " (('the', 'way'), 123),\n",
       " (('of', 'other'), 123),\n",
       " (('is', 'used'), 123),\n",
       " (('came', 'to'), 123),\n",
       " (('had', 'the'), 123),\n",
       " (('on', 'which'), 122),\n",
       " (('that', 'this'), 122),\n",
       " (('where', 'it'), 122),\n",
       " (('the', 'rest'), 122),\n",
       " (('daughter', 'of'), 122),\n",
       " (('was', 'at'), 121),\n",
       " (('of', 'July'), 121),\n",
       " (('the', 'greatest'), 121),\n",
       " (('been', 'made'), 121),\n",
       " (('than', 'that'), 121),\n",
       " (('have', 'no'), 121),\n",
       " (('a', 'series'), 121),\n",
       " (('which', 'in'), 121),\n",
       " (('the', '17th'), 121),\n",
       " (('city', 'of'), 121),\n",
       " (('The', 'most'), 121),\n",
       " (('since', 'the'), 121),\n",
       " (('with', 'its'), 121),\n",
       " (('of', 'whom'), 121),\n",
       " (('|', '|'), 120),\n",
       " (('like', 'the'), 120),\n",
       " (('of', 'many'), 120),\n",
       " (('them', 'in'), 120),\n",
       " (('together', 'with'), 120),\n",
       " (('as', 'is'), 120),\n",
       " (('and', 'they'), 120),\n",
       " (('By', 'the'), 120),\n",
       " (('born', 'in'), 120),\n",
       " (('his', 'father'), 120),\n",
       " (('in', 'other'), 120),\n",
       " (('no', 'more'), 120),\n",
       " (('we', 'are'), 119),\n",
       " (('divided', 'into'), 119),\n",
       " (('belonging', 'to'), 119),\n",
       " (('the', 'ordinary'), 119),\n",
       " (('at', 'first'), 119),\n",
       " (('Of', 'The'), 119),\n",
       " (('addition', 'to'), 118),\n",
       " (('that', 'his'), 118),\n",
       " (('necessary', 'to'), 118),\n",
       " (('The', 'chief'), 118),\n",
       " (('right', 'to'), 118),\n",
       " (('but', 'by'), 118),\n",
       " (('the', 'presence'), 117),\n",
       " (('but', 'his'), 117),\n",
       " (('ought', 'to'), 117),\n",
       " (('formation', 'of'), 117),\n",
       " (('applied', 'to'), 117),\n",
       " (('manufacture', 'of'), 117),\n",
       " (('an', 'important'), 117),\n",
       " (('After', 'the'), 117),\n",
       " (('the', 'three'), 117),\n",
       " (('sent', 'to'), 117),\n",
       " (('so', 'as'), 117),\n",
       " (('or', 'less'), 116),\n",
       " (('of', 'March'), 116),\n",
       " (('This', 'was'), 116),\n",
       " (('not', 'in'), 116),\n",
       " (('author', 'of'), 116),\n",
       " (('And', 'therefore'), 116),\n",
       " (('but', 'not'), 115),\n",
       " (('the', 'modern'), 115),\n",
       " (('to', 'do'), 115),\n",
       " (('his', 'death'), 115),\n",
       " (('of', 'December'), 115),\n",
       " (('the', 'Kingdome'), 115),\n",
       " (('a', 'general'), 114),\n",
       " (('the', 'later'), 114),\n",
       " (('of', 'April'), 114),\n",
       " (('path', '.'), 114),\n",
       " (('the', 'public'), 113),\n",
       " (('the', 'world'), 113),\n",
       " (('right', 'of'), 113),\n",
       " (('followed', 'by'), 113),\n",
       " (('from', 'that'), 113),\n",
       " (('given', 'by'), 113),\n",
       " (('hands', 'of'), 113),\n",
       " (('our', 'Saviour'), 113),\n",
       " (('when', 'a'), 112),\n",
       " (('To', 'the'), 112),\n",
       " (('When', 'the'), 112),\n",
       " (('and', 'many'), 112),\n",
       " (('of', 'January'), 112),\n",
       " (('age', 'of'), 112),\n",
       " (('the', '12th'), 112),\n",
       " (('the', 'hands'), 112),\n",
       " (('of', 'May'), 112),\n",
       " (('not', 'onely'), 112),\n",
       " (('throughout', 'the'), 111),\n",
       " (('the', 'mouth'), 111),\n",
       " (('degree', 'of'), 111),\n",
       " (('became', 'the'), 111),\n",
       " (('been', 'the'), 111),\n",
       " (('the', '15th'), 111),\n",
       " (('life', 'of'), 111),\n",
       " (('battle', 'of'), 111),\n",
       " (('all', 'other'), 110),\n",
       " (('more', 'or'), 110),\n",
       " (('bank', 'of'), 110),\n",
       " (('capital', 'of'), 110),\n",
       " (('but', 'that'), 110),\n",
       " (('the', 'true'), 109),\n",
       " (('as', 'his'), 109),\n",
       " (('He', 'is'), 109),\n",
       " (('the', '13th'), 109),\n",
       " (('it', 'had'), 109),\n",
       " (('the', 'course'), 109),\n",
       " (('whole', 'of'), 109),\n",
       " (('the', 'act'), 109),\n",
       " (('is', 'more'), 108),\n",
       " (('and', 'even'), 108),\n",
       " (('to', 'some'), 108),\n",
       " (('place', 'in'), 108),\n",
       " (('of', 'September'), 108),\n",
       " (('had', 'not'), 108),\n",
       " (('and', 'consequently'), 108),\n",
       " (('the', 'period'), 108),\n",
       " (('character', 'of'), 108),\n",
       " (('the', 'High'), 108),\n",
       " (('the', 'question'), 108),\n",
       " (('contrary', 'to'), 108),\n",
       " (('is', 'given'), 107),\n",
       " (('was', 'one'), 107),\n",
       " (('come', 'to'), 107),\n",
       " (('after', 'his'), 107),\n",
       " (('him', 'that'), 107),\n",
       " (('only', 'a'), 106),\n",
       " (('terms', 'of'), 106),\n",
       " (('is', 'generally'), 106),\n",
       " (('rather', 'than'), 105),\n",
       " (('which', 'may'), 105),\n",
       " (('are', 'found'), 105),\n",
       " (('professor', 'of'), 105),\n",
       " (('a', 'member'), 105),\n",
       " (('was', 'sent'), 105),\n",
       " (('man', 'of'), 105),\n",
       " (('also', 'a'), 105),\n",
       " (('church', 'of'), 105),\n",
       " (('the', 'duke'), 105),\n",
       " (('idea', 'of'), 105),\n",
       " (('the', 'battle'), 105),\n",
       " (('was', 'no'), 105),\n",
       " (('way', 'of'), 105),\n",
       " (('the', 'one'), 104),\n",
       " (('a', 'little'), 104),\n",
       " (('as', 'much'), 104),\n",
       " (('forms', 'of'), 104),\n",
       " (('the', 'close'), 104),\n",
       " (('attached', 'to'), 104),\n",
       " (('no', 'other'), 104),\n",
       " (('and', 'one'), 103),\n",
       " (('must', 'have'), 103),\n",
       " (('were', 'to'), 103),\n",
       " (('a', 'short'), 103),\n",
       " (('those', 'who'), 103),\n",
       " (('the', 'Old'), 103),\n",
       " (('the', 'body'), 103),\n",
       " (('rest', 'of'), 103),\n",
       " (('favour', 'of'), 103),\n",
       " (('the', 'age'), 103),\n",
       " (('m.', 'from'), 103),\n",
       " (('of', 'men'), 103),\n",
       " (('cause', 'of'), 103),\n",
       " (('of', 'June'), 103),\n",
       " (('division', 'of'), 103),\n",
       " (('from', 'its'), 102),\n",
       " (('with', 'their'), 102),\n",
       " (('also', 'to'), 102),\n",
       " (('remains', 'of'), 102),\n",
       " (('was', 'first'), 102),\n",
       " (('form', 'a'), 102),\n",
       " (('path.', '.'), 102),\n",
       " (('to', 'one'), 101),\n",
       " (('him', 'the'), 101),\n",
       " (('is', 'about'), 101),\n",
       " (('so', 'much'), 101),\n",
       " (('result', 'of'), 101),\n",
       " (('who', 'were'), 101),\n",
       " (('bishop', 'of'), 101),\n",
       " (('method', 'of'), 101),\n",
       " (('Col', 'de'), 101),\n",
       " (('is', 'so'), 100),\n",
       " (('though', 'it'), 100),\n",
       " (('is', 'often'), 100),\n",
       " (('him,', 'and'), 100),\n",
       " (('names', 'of'), 100),\n",
       " (('across', 'the'), 100),\n",
       " (('himself', 'to'), 100),\n",
       " (('the', '4th'), 100),\n",
       " (('of', 'October'), 100),\n",
       " (('only', 'to'), 100),\n",
       " (('of', 'what'), 100),\n",
       " (('were', 'in'), 100),\n",
       " (('command', 'of'), 100),\n",
       " (('be', 'taken'), 100),\n",
       " (('the', 'sea'), 99),\n",
       " (('at', 'his'), 99),\n",
       " (('spite', 'of'), 99),\n",
       " (('the', 'manufacture'), 99),\n",
       " (('at', 'this'), 99),\n",
       " (('from', 'their'), 99),\n",
       " (('whom', 'the'), 99),\n",
       " (('also', 'in'), 99),\n",
       " (('of', 'November'), 99),\n",
       " (('mouth', 'of'), 99),\n",
       " (('supposed', 'to'), 99),\n",
       " (('which', 'we'), 98),\n",
       " (('if', 'they'), 98),\n",
       " (('the', 'purpose'), 98),\n",
       " (('purpose', 'of'), 98),\n",
       " (('branch', 'of'), 98),\n",
       " (('any', 'of'), 98),\n",
       " (('the', 'earliest'), 98),\n",
       " (('west', 'of'), 98),\n",
       " (('sq.', 'm.'), 98),\n",
       " (('the', 'Great'), 98),\n",
       " (('the', 'Spanish'), 98),\n",
       " (('of', 'February'), 98),\n",
       " (('was', 'given'), 98),\n",
       " (('treaty', 'of'), 98),\n",
       " (('to', 'say'), 98),\n",
       " (('deg.', 'C.'), 98),\n",
       " (('and', 'most'), 97),\n",
       " (('is', 'made'), 97),\n",
       " (('The', 'name'), 97),\n",
       " (('close', 'of'), 97),\n",
       " (('both', 'in'), 97),\n",
       " (('have', 'not'), 97),\n",
       " (('to', 'obtain'), 96),\n",
       " (('especially', 'in'), 96),\n",
       " (('for', 'this'), 96),\n",
       " (('the', 'formation'), 96),\n",
       " (('used', 'to'), 96),\n",
       " (('the', 'law'), 96),\n",
       " (('the', 'university'), 96),\n",
       " (('the', '14th'), 96),\n",
       " (('to', 'them'), 96),\n",
       " (('by', 'some'), 96),\n",
       " (('would', 'have'), 96),\n",
       " (('the', 'island'), 96),\n",
       " (('theory', 'of'), 96),\n",
       " (('the', 'Church'), 96),\n",
       " (('way', 'to'), 95),\n",
       " (('allowed', 'to'), 95),\n",
       " (('some', 'time'), 95),\n",
       " (('than', 'a'), 95),\n",
       " (('The', 'same'), 95),\n",
       " (('to', 'keep'), 95),\n",
       " (('a', 'second'), 95),\n",
       " (('absence', 'of'), 95),\n",
       " (('collection', 'of'), 95),\n",
       " (('solution', 'of'), 95),\n",
       " (('because', 'the'), 95),\n",
       " (('the', 'person'), 95),\n",
       " (('a', 'fine'), 94),\n",
       " (('is', 'only'), 94),\n",
       " (('matter', 'of'), 94),\n",
       " (('They', 'were'), 94),\n",
       " (('the', 'names'), 94),\n",
       " (('given', 'in'), 94),\n",
       " (('was', 'published'), 94),\n",
       " (('reign', 'of'), 94),\n",
       " (('however,', 'the'), 94),\n",
       " (('attributed', 'to'), 94),\n",
       " (('consequence', 'of'), 94),\n",
       " (('the', 'Congo'), 94),\n",
       " (('in', 'these'), 93),\n",
       " (('because', 'they'), 93),\n",
       " (('As', 'a'), 93),\n",
       " (('edited', 'by'), 93),\n",
       " (('his', 'life'), 93),\n",
       " (('and', 'had'), 93),\n",
       " (('the', 'study'), 93),\n",
       " (('Among', 'the'), 93),\n",
       " (('founded', 'in'), 93),\n",
       " (('the', '5th'), 93),\n",
       " (('the', 'value'), 93),\n",
       " (('the', 'higher'), 93),\n",
       " (('the', 'influence'), 93),\n",
       " (('every', 'man'), 93),\n",
       " (('but', 'of'), 92),\n",
       " (('are', 'very'), 92),\n",
       " (('be', 'said'), 92),\n",
       " (('but', 'they'), 92),\n",
       " (('a', 'special'), 92),\n",
       " (('has', 'not'), 92),\n",
       " (('the', '6th'), 92),\n",
       " (('and', 'afterwards'), 92),\n",
       " (('continued', 'to'), 92),\n",
       " (('went', 'to'), 92),\n",
       " (('subject', 'of'), 92),\n",
       " (('body', 'of'), 92),\n",
       " (('the', 'words'), 92),\n",
       " (('the', 'site'), 92),\n",
       " (('the', 'council'), 92),\n",
       " (('If', 'the'), 92),\n",
       " (('the', 'central'), 92),\n",
       " (('composed', 'of'), 92),\n",
       " (('existence', 'of'), 92),\n",
       " (('as', 'are'), 92),\n",
       " (('species', 'of'), 91),\n",
       " (('only', 'in'), 91),\n",
       " (('valley', 'of'), 91),\n",
       " (('down', 'to'), 91),\n",
       " (('but', 'was'), 91),\n",
       " (('ft.', 'above'), 91),\n",
       " (('As', 'the'), 91),\n",
       " (('Court', 'of'), 91),\n",
       " (('men', 'to'), 91),\n",
       " (('the', 'royal'), 91),\n",
       " (('or', 'more'), 91),\n",
       " (('the', '1st'), 91),\n",
       " (('United', 'States,'), 90),\n",
       " (('used', 'as'), 90),\n",
       " (('as', 'if'), 90),\n",
       " (('he', 'has'), 90),\n",
       " (('the', 'Indian'), 90),\n",
       " (('is', 'probably'), 90),\n",
       " (('the', 'earlier'), 90),\n",
       " (('seat', 'of'), 90),\n",
       " (('a', 'time'), 90),\n",
       " (('district', 'of'), 90),\n",
       " (('these', 'are'), 90),\n",
       " (('a', 'part'), 90),\n",
       " (('department', 'of'), 90),\n",
       " (('made', 'the'), 90),\n",
       " (('was', 'founded'), 90),\n",
       " (('and', 'thus'), 90),\n",
       " (('every', 'one'), 89),\n",
       " (('are', 'a'), 89),\n",
       " (('on', 'account'), 89),\n",
       " (('the', 'Christian'), 89),\n",
       " (('time', 'the'), 89),\n",
       " (('authority', 'of'), 89),\n",
       " (('position', 'of'), 89),\n",
       " (('we', 'may'), 89),\n",
       " (('men', 'of'), 89),\n",
       " (('attempt', 'to'), 89),\n",
       " (('being', 'a'), 89),\n",
       " (('height', 'of'), 89),\n",
       " (('school', 'of'), 89),\n",
       " (('of', 'Nature,'), 89),\n",
       " (('up', 'in'), 88),\n",
       " (('much', 'more'), 88),\n",
       " (('for', 'that'), 88),\n",
       " (('much', 'as'), 88),\n",
       " (('or', 'any'), 88),\n",
       " (('the', 'terms'), 88),\n",
       " (('associated', 'with'), 88),\n",
       " (('not', 'of'), 88),\n",
       " (('He', 'had'), 88),\n",
       " (('he', 'took'), 88),\n",
       " (('earl', 'of'), 88),\n",
       " (('be', 'in'), 88),\n",
       " (('no', 'longer'), 88),\n",
       " (('rise', 'to'), 88),\n",
       " (('all', 'that'), 87),\n",
       " (('view', 'of'), 87),\n",
       " (('first', 'of'), 87),\n",
       " (('not', 'so'), 87),\n",
       " (('as', 'that'), 87),\n",
       " (('want', 'of'), 87),\n",
       " (('first', 'to'), 87),\n",
       " (('this', 'time'), 87),\n",
       " (('in', 'every'), 87),\n",
       " (('edition', 'of'), 87),\n",
       " (('not', 'been'), 87),\n",
       " (('the', 'North'), 87),\n",
       " (('description', 'of'), 87),\n",
       " (('through', 'a'), 87),\n",
       " (('power', 'to'), 87),\n",
       " (('had', 'no'), 87),\n",
       " (('no', 'man'), 87),\n",
       " (('the', 'interior'), 87),\n",
       " (('they', 'that'), 87),\n",
       " (('OF', 'THE'), 86),\n",
       " (('greater', 'part'), 86),\n",
       " (('has', 'the'), 86),\n",
       " (('the', 'largest'), 86),\n",
       " (('for', 'an'), 86),\n",
       " (('the', 'left'), 86),\n",
       " (('council', 'of'), 86),\n",
       " (('the', 'high'), 86),\n",
       " (('and', 'were'), 86),\n",
       " (('house', 'of'), 86),\n",
       " (('occupied', 'by'), 86),\n",
       " (('were', 'made'), 86),\n",
       " (('snow', '.'), 86),\n",
       " (('enough', 'to'), 85),\n",
       " (('half', 'of'), 85),\n",
       " (('be', 'no'), 85),\n",
       " (('are', 'now'), 85),\n",
       " (('succeeded', 'in'), 85),\n",
       " (('than', 'in'), 85),\n",
       " (('it', 'would'), 85),\n",
       " (('much', 'of'), 85),\n",
       " (('who', 'is'), 85),\n",
       " (('received', 'the'), 85),\n",
       " (('took', 'the'), 85),\n",
       " (('of', 'British'), 85),\n",
       " (('site', 'of'), 85),\n",
       " (('variety', 'of'), 85),\n",
       " (('been', 'a'), 85),\n",
       " (('the', 'total'), 85),\n",
       " (('obtained', 'by'), 85),\n",
       " (('the', 'continent'), 84),\n",
       " (('production', 'of'), 84),\n",
       " (('on', 'this'), 84),\n",
       " (('kinds', 'of'), 84),\n",
       " (('that', 'had'), 84),\n",
       " (('concerning', 'the'), 84),\n",
       " (('be', 'regarded'), 84),\n",
       " (('be', 'of'), 84),\n",
       " (('is', 'usually'), 83),\n",
       " (('the', 'very'), 83),\n",
       " (('the', 'small'), 83),\n",
       " ...]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fd0d820c-f94f-43a8-bde6-4f5e5044a06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "48fa6f09-6320-4d94-b8eb-1c05caf8b6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(255, dtype=torch.uint8)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[1843, 650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "13260b47-b9c8-4d89-9a65-f1d5c099d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N / N.sum(dim = 1, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8bf14bba-96fa-4ea9-9513-be489b38ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss\n",
      "log Likelihood: -2868851.75\n",
      "Negative log likelihood: 2868851.75\n",
      "Normalized Negative log Likelihood: 4.003024578094482\n",
      " have shown that has the name has changed the outer boundary was obliged to carry the coast, where every little railway from nearly every fresh attack on this, with reference to pay what his children were mainly by which had resistance it to take any part of our work in other intellectual than his personal history of September of metal war, afterwards visited the books (see further extended from those places of life by sea was raised from a school and afterwards he returned to represent nothing to which he took it by them seems to Germany, in proportion of of that it was reduced charge a place at his town and all of local authorities are remarkable for her tendency to matters known as being the cell in time at present time has an important is the knowledge of that is, the earl of these can he is generally termed an area of beauty is never have derived from appearance of What The chief of June to them, the long range of about to J. H. T. G. F. average yield good English name was an increase in Great Britain since they made known as are four years or\n",
      "Sampled words Loss\n",
      "log Likelihood: -2868851.75\n",
      "Negative log likelihood: 2868851.75\n",
      "Normalized Negative log Likelihood: 4.003024578094482\n"
     ]
    }
   ],
   "source": [
    "def count_loss(input_list, verbose = False):\n",
    "    log_likelihood = 0.0\n",
    "    n = 0\n",
    "    for w1, w2 in zip(words, words[1:]):\n",
    "        if w1 in uwords and w2 in uwords:\n",
    "            ix1 = wtoi[w1]\n",
    "            ix2 = wtoi[w2]\n",
    "\n",
    "            prob = P[ix1, ix2]\n",
    "            logprob = torch.log(prob)\n",
    "            log_likelihood += logprob\n",
    "            n += 1\n",
    "\n",
    "    # higher the log likelihood (closer to 0) is better\n",
    "    print(f\"log Likelihood: {log_likelihood}\")\n",
    "\n",
    "    # but in loss function lower is better, so we negate it\n",
    "    nll = -log_likelihood\n",
    "    print(f\"Negative log likelihood: {nll}\")\n",
    "\n",
    "    # normalize it\n",
    "    print(f\"Normalized Negative log Likelihood: {(nll / n)}\") # we need to minimize this\n",
    "    \n",
    "    \n",
    "print(\"Training Loss\")\n",
    "count_loss(words)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "# Sampling\n",
    "sample = \"\"\n",
    "for i in range(10):\n",
    "\n",
    "    ix = 0\n",
    "    for j in range(20):\n",
    "        p = P[ix]\n",
    "\n",
    "        ix = torch.multinomial(p, 1, replacement=True).item()\n",
    "        sample += \" \" + itow[ix]\n",
    "\n",
    "\n",
    "    \n",
    "print(sample)\n",
    "print(\"Sampled words Loss\")\n",
    "count_loss(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c457c-e5e4-4aee-9421-f22ab2888abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
