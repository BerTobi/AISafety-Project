{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe2206f-832e-47b8-bb07-8af3dbf4b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('Dataset/English/Encyclopedia.txt', 'r').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53136844-1167-426f-b68b-86a23e6d27cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'Encyclopedia,',\n",
       " 'Volume']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e19c5804-fc7d-46b5-ba8f-f594dd50ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1348581"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61727414-feaa-4248-938f-e26acac1b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list (w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14954be7-550c-4601-9e96-c2f884ef04ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('e', '<E>'), 243715),\n",
       " (('<S>', 't'), 187349),\n",
       " (('t', 'h'), 173633),\n",
       " (('h', 'e'), 167157),\n",
       " (('<S>', 'a'), 145041),\n",
       " (('s', '<E>'), 142834),\n",
       " (('d', '<E>'), 116414),\n",
       " (('i', 'n'), 113371),\n",
       " (('n', '<E>'), 113357),\n",
       " (('<S>', 'o'), 110535),\n",
       " (('a', 'n'), 104065),\n",
       " ((',', '<E>'), 102374),\n",
       " (('e', 'r'), 101424),\n",
       " (('t', '<E>'), 85448),\n",
       " (('r', 'e'), 83994),\n",
       " (('.', '<E>'), 83709),\n",
       " (('o', 'n'), 80662),\n",
       " (('<S>', 'i'), 79112),\n",
       " (('f', '<E>'), 76998),\n",
       " (('o', 'f'), 76115),\n",
       " (('n', 'd'), 72133),\n",
       " (('e', 'n'), 66573),\n",
       " (('a', 't'), 64826),\n",
       " (('e', 's'), 64466),\n",
       " (('e', 'd'), 63373),\n",
       " (('y', '<E>'), 62919),\n",
       " (('o', 'r'), 61028),\n",
       " (('<S>', 'w'), 60734),\n",
       " (('i', 's'), 60361),\n",
       " (('<S>', 's'), 59640),\n",
       " (('t', 'i'), 58544),\n",
       " (('a', 'r'), 58467),\n",
       " (('t', 'e'), 58405),\n",
       " (('r', '<E>'), 56723),\n",
       " (('<S>', 'c'), 52998),\n",
       " (('a', 'l'), 52268),\n",
       " (('i', 't'), 50739),\n",
       " (('s', 't'), 50594),\n",
       " (('<S>', 'b'), 50500),\n",
       " (('n', 't'), 47621),\n",
       " (('t', 'o'), 46470),\n",
       " (('a', 's'), 46184),\n",
       " (('<S>', 'f'), 44221),\n",
       " (('r', 'i'), 44170),\n",
       " (('o', '<E>'), 44107),\n",
       " (('<S>', 'p'), 43150),\n",
       " (('<S>', 'h'), 40800),\n",
       " (('l', 'e'), 39728),\n",
       " (('d', 'e'), 39465),\n",
       " (('s', 'e'), 39177),\n",
       " (('h', 'i'), 39052),\n",
       " (('n', 'g'), 38541),\n",
       " (('h', '<E>'), 37779),\n",
       " (('i', 'c'), 37179),\n",
       " (('r', 'a'), 36957),\n",
       " (('r', 'o'), 35713),\n",
       " (('i', 'o'), 34593),\n",
       " (('c', 'o'), 34105),\n",
       " (('a', '<E>'), 33824),\n",
       " (('o', 'u'), 33822),\n",
       " (('m', 'e'), 33482),\n",
       " (('<S>', 'm'), 32986),\n",
       " (('v', 'e'), 32899),\n",
       " (('h', 'a'), 32876),\n",
       " (('c', 'e'), 32588),\n",
       " (('c', 'h'), 31895),\n",
       " (('e', 'a'), 31723),\n",
       " (('<S>', 'd'), 31677),\n",
       " (('l', '<E>'), 31439),\n",
       " (('n', 'e'), 31060),\n",
       " (('l', 'a'), 28394),\n",
       " (('<S>', 'r'), 27563),\n",
       " (('<S>', 'A'), 27516),\n",
       " (('l', 'l'), 27216),\n",
       " (('<S>', 'e'), 27089),\n",
       " (('l', 'i'), 27030),\n",
       " (('u', 'r'), 26870),\n",
       " (('b', 'e'), 26730),\n",
       " (('t', 'a'), 26654),\n",
       " (('o', 'm'), 26308),\n",
       " (('g', '<E>'), 25114),\n",
       " (('m', 'a'), 24771),\n",
       " (('n', 's'), 24034),\n",
       " (('d', 'i'), 23877),\n",
       " (('e', 'l'), 23066),\n",
       " (('<S>', 'l'), 22932),\n",
       " (('c', 'a'), 22788),\n",
       " (('s', 'i'), 22761),\n",
       " (('u', 's'), 22539),\n",
       " (('a', 'c'), 21452),\n",
       " (('w', 'a'), 20909),\n",
       " (('f', 'o'), 20670),\n",
       " (('r', 't'), 20649),\n",
       " (('i', 'e'), 20525),\n",
       " (('l', 'y'), 20475),\n",
       " (('<S>', 'T'), 20303),\n",
       " (('n', 'c'), 20278),\n",
       " (('c', 't'), 20224),\n",
       " (('h', 'o'), 20079),\n",
       " (('t', 'r'), 20003),\n",
       " (('s', ','), 19940),\n",
       " (('e', 'c'), 19843),\n",
       " (('<S>', '1'), 19802),\n",
       " (('u', 't'), 19677),\n",
       " (('i', 'l'), 19394),\n",
       " (('<S>', 'n'), 19225),\n",
       " (('p', 'e'), 19219),\n",
       " (('s', 's'), 18949),\n",
       " (('p', 'r'), 18784),\n",
       " (('i', 'a'), 18697),\n",
       " (('u', 'n'), 18688),\n",
       " (('w', 'h'), 18680),\n",
       " (('o', 'l'), 18316),\n",
       " (('r', 's'), 18159),\n",
       " (('e', 't'), 17856),\n",
       " (('n', 'a'), 17824),\n",
       " (('l', 'o'), 17812),\n",
       " (('g', 'e'), 17458),\n",
       " (('m', '<E>'), 17382),\n",
       " (('s', 'o'), 17022),\n",
       " (('n', 'i'), 16979),\n",
       " (('a', 'd'), 16901),\n",
       " (('a', 'i'), 16885),\n",
       " (('p', 'o'), 16866),\n",
       " (('e', 'e'), 16815),\n",
       " (('t', 's'), 16687),\n",
       " (('n', 'o'), 16634),\n",
       " (('<S>', '('), 16545),\n",
       " (('o', 't'), 16459),\n",
       " (('e', 'm'), 16452),\n",
       " (('T', 'h'), 16033),\n",
       " (('i', 'r'), 15297),\n",
       " (('o', 'w'), 15227),\n",
       " (('m', 'o'), 15106),\n",
       " (('o', 's'), 15023),\n",
       " (('a', 'm'), 15011),\n",
       " (('<S>', '.'), 14830),\n",
       " (('w', 'e'), 14761),\n",
       " (('i', 'm'), 14574),\n",
       " (('<S>', 'g'), 14524),\n",
       " (('w', 'i'), 14358),\n",
       " (('<S>', 'S'), 14356),\n",
       " (('b', 'y'), 14268),\n",
       " (('m', 'i'), 14007),\n",
       " (('r', 'y'), 13878),\n",
       " (('c', 'i'), 13865),\n",
       " (('s', 'h'), 13641),\n",
       " (('u', 'l'), 13586),\n",
       " (('p', 'a'), 13502),\n",
       " (('s', 'u'), 13396),\n",
       " (('i', 'd'), 13279),\n",
       " (('e', ','), 13185),\n",
       " (('t', 'u'), 13140),\n",
       " (('<S>', 'C'), 12774),\n",
       " (('i', 'v'), 12715),\n",
       " (('a', 'b'), 12697),\n",
       " (('<S>', 'I'), 12144),\n",
       " (('i', 'g'), 11379),\n",
       " (('f', 'i'), 11358),\n",
       " (('s', '.'), 11106),\n",
       " (('f', 'r'), 11068),\n",
       " (('1', '8'), 10934),\n",
       " (('<S>', 'B'), 10819),\n",
       " (('v', 'i'), 10777),\n",
       " (('<S>', 'u'), 10723),\n",
       " (('m', 'p'), 10723),\n",
       " ((';', '<E>'), 10686),\n",
       " (('r', 'd'), 10540),\n",
       " (('o', 'p'), 10506),\n",
       " (('b', 'l'), 10488),\n",
       " (('e', 'i'), 10220),\n",
       " (('<S>', 'v'), 10103),\n",
       " (('e', 'x'), 10100),\n",
       " (('p', 'l'), 9813),\n",
       " (('<S>', 'M'), 9760),\n",
       " (('r', 'm'), 9654),\n",
       " (('<S>', 'P'), 9653),\n",
       " (('g', 'h'), 9646),\n",
       " (('<S>', 'H'), 9543),\n",
       " (('a', 'g'), 9285),\n",
       " (('t', 'y'), 9254),\n",
       " (('b', 'u'), 9181),\n",
       " (('b', 'o'), 9140),\n",
       " (('g', 'r'), 8922),\n",
       " (('t', 't'), 8898),\n",
       " (('n', ','), 8847),\n",
       " (('r', 'n'), 8841),\n",
       " (('u', 'c'), 8830),\n",
       " (('o', 'd'), 8829),\n",
       " (('e', 'v'), 8784),\n",
       " (('f', 'e'), 8708),\n",
       " (('a', 'v'), 8565),\n",
       " (('a', 'p'), 8493),\n",
       " (('u', 'm'), 8471),\n",
       " (('s', 'a'), 8460),\n",
       " (('g', 'a'), 8105),\n",
       " (('l', 'd'), 7861),\n",
       " (('c', 'u'), 7836),\n",
       " (('s', 'c'), 7712),\n",
       " (('e', 'p'), 7672),\n",
       " (('o', 'v'), 7661),\n",
       " (('<S>', 'G'), 7651),\n",
       " (('g', 'i'), 7614),\n",
       " (('l', 's'), 7564),\n",
       " (('v', 'a'), 7511),\n",
       " (('o', 'o'), 7422),\n",
       " (('s', 'p'), 7373),\n",
       " (('u', 'e'), 7334),\n",
       " (('e', '.'), 7294),\n",
       " (('o', 'c'), 7284),\n",
       " (('<S>', 'E'), 7252),\n",
       " (('w', 'o'), 7215),\n",
       " (('e', 'f'), 7103),\n",
       " (('d', ','), 7079),\n",
       " (('e', 'g'), 7073),\n",
       " (('f', 'a'), 6925),\n",
       " (('r', ','), 6893),\n",
       " (('<S>', 'F'), 6871),\n",
       " (('a', 'y'), 6866),\n",
       " (('d', 's'), 6794),\n",
       " (('<S>', 'L'), 6792),\n",
       " (('d', 'o'), 6775),\n",
       " (('d', 'u'), 6678),\n",
       " (('k', 'e'), 6667),\n",
       " (('b', 'a'), 6653),\n",
       " (('l', 'u'), 6631),\n",
       " (('r', 'r'), 6620),\n",
       " (('q', 'u'), 6586),\n",
       " (('l', 't'), 6562),\n",
       " (('c', 'l'), 6461),\n",
       " (('i', 'f'), 6411),\n",
       " (('c', '<E>'), 6408),\n",
       " (('d', 'a'), 6370),\n",
       " (('t', ','), 6356),\n",
       " (('c', 'r'), 6352),\n",
       " (('u', 'g'), 6305),\n",
       " (('y', ','), 6287),\n",
       " ((')', '<E>'), 6230),\n",
       " (('p', 'p'), 6165),\n",
       " (('r', 'c'), 6153),\n",
       " (('r', 'u'), 6146),\n",
       " (('u', 'a'), 6126),\n",
       " (('p', 'i'), 6091),\n",
       " (('<S>', 'R'), 6086),\n",
       " (('c', 'c'), 5978),\n",
       " (('r', 'g'), 5799),\n",
       " (('w', '<E>'), 5781),\n",
       " (('u', 'p'), 5764),\n",
       " (('I', 'n'), 5690),\n",
       " (('f', 'f'), 5685),\n",
       " ((')', ','), 5671),\n",
       " (('t', 'l'), 5636),\n",
       " (('p', 'h'), 5613),\n",
       " (('a', 'u'), 5591),\n",
       " (('m', 'b'), 5580),\n",
       " (('b', 'r'), 5547),\n",
       " (('k', '<E>'), 5422),\n",
       " (('e', 'y'), 5350),\n",
       " (('u', 'i'), 5282),\n",
       " (('A', 'l'), 5255),\n",
       " (('m', 'm'), 5192),\n",
       " (('t', '.'), 5178),\n",
       " (('u', 'b'), 5171),\n",
       " (('p', 't'), 5137),\n",
       " (('<S>', 'N'), 5082),\n",
       " (('<S>', 'D'), 5036),\n",
       " (('f', 't'), 5022),\n",
       " (('n', 'u'), 5010),\n",
       " (('p', 'u'), 4969),\n",
       " (('i', 'b'), 4939),\n",
       " (('<S>', 'W'), 4706),\n",
       " (('w', 'n'), 4704),\n",
       " (('h', 't'), 4704),\n",
       " (('r', 'l'), 4661),\n",
       " (('d', '.'), 4636),\n",
       " (('i', 'p'), 4622),\n",
       " (('b', 'i'), 4572),\n",
       " (('n', '.'), 4556),\n",
       " (('-', '-'), 4480),\n",
       " (('a', ','), 4477),\n",
       " (('h', 'r'), 4397),\n",
       " (('o', 'i'), 4364),\n",
       " (('n', 'y'), 4347),\n",
       " (('m', 'u'), 4337),\n",
       " ((\"'\", '<E>'), 4329),\n",
       " (('r', 'k'), 4327),\n",
       " (('g', 'o'), 4281),\n",
       " (('o', 'g'), 4273),\n",
       " (('<S>', 'O'), 4261),\n",
       " ((\"'\", \"'\"), 4227),\n",
       " (('o', 'b'), 4226),\n",
       " (('<S>', 'J'), 4199),\n",
       " (('`', '`'), 4194),\n",
       " (('0', '<E>'), 4179),\n",
       " (('e', 'w'), 4166),\n",
       " (('(', '1'), 4161),\n",
       " (('g', 'u'), 4151),\n",
       " (('<S>', '`'), 4124),\n",
       " (('m', 's'), 4095),\n",
       " (('v', 'o'), 4083),\n",
       " (('n', 'n'), 4074),\n",
       " (('t', 'w'), 4073),\n",
       " (('C', 'o'), 4041),\n",
       " (('y', 's'), 4026),\n",
       " (('0', '0'), 4022),\n",
       " (('M', 'a'), 4005),\n",
       " (('H', 'e'), 3962),\n",
       " (('<S>', 'k'), 3954),\n",
       " (('y', 'e'), 3945),\n",
       " (('a', 'k'), 3898),\n",
       " (('c', 'k'), 3885),\n",
       " (('u', 'd'), 3827),\n",
       " (('d', 'r'), 3765),\n",
       " ((\"'\", 's'), 3750),\n",
       " (('k', 'i'), 3694),\n",
       " (('h', 'u'), 3650),\n",
       " (('f', 'u'), 3622),\n",
       " (('g', 'l'), 3517),\n",
       " (('e', 'o'), 3517),\n",
       " (('<S>', '2'), 3473),\n",
       " (('I', 't'), 3455),\n",
       " (('a', 'f'), 3398),\n",
       " (('y', '.'), 3396),\n",
       " (('<S>', 'y'), 3363),\n",
       " (('g', 'n'), 3348),\n",
       " (('p', '<E>'), 3205),\n",
       " (('r', '.'), 3149),\n",
       " (('f', 'l'), 3096),\n",
       " (('a', 'e'), 3095),\n",
       " (('i', 'z'), 3070),\n",
       " (('1', '9'), 2970),\n",
       " (('o', 'a'), 2950),\n",
       " (('F', 'r'), 2950),\n",
       " (('s', 'l'), 2924),\n",
       " (('n', 'l'), 2882),\n",
       " (('9', '0'), 2863),\n",
       " (('l', ','), 2832),\n",
       " (('r', 'v'), 2821),\n",
       " (('1', '7'), 2817),\n",
       " (('C', 'a'), 2785),\n",
       " (('h', 'y'), 2763),\n",
       " (('n', 'f'), 2760),\n",
       " (('k', 's'), 2744),\n",
       " (('8', '9'), 2737),\n",
       " (('i', 'u'), 2706),\n",
       " (('<S>', 'V'), 2662),\n",
       " ((')', '.'), 2649),\n",
       " (('x', 't'), 2637),\n",
       " (('<S>', 'K'), 2593),\n",
       " (('z', 'e'), 2591),\n",
       " (('x', 'i'), 2586),\n",
       " (('C', 'h'), 2577),\n",
       " (('h', ','), 2575),\n",
       " (('G', 'r'), 2569),\n",
       " (('b', 's'), 2535),\n",
       " (('A', 'n'), 2532),\n",
       " (('s', 'm'), 2509),\n",
       " (('S', 't'), 2495),\n",
       " (('B', 'r'), 2469),\n",
       " (('x', 'p'), 2435),\n",
       " (('p', 's'), 2427),\n",
       " (('m', '.'), 2421),\n",
       " (('A', 'm'), 2412),\n",
       " (('P', 'a'), 2409),\n",
       " (('i', '<E>'), 2406),\n",
       " (('<S>', '3'), 2361),\n",
       " (('l', 'f'), 2289),\n",
       " (('g', 's'), 2273),\n",
       " (('.', ','), 2264),\n",
       " (('R', 'o'), 2227),\n",
       " (('S', 'e'), 2196),\n",
       " (('i', '.'), 2166),\n",
       " (('l', '.'), 2139),\n",
       " (('a', 'w'), 2112),\n",
       " (('e', 'q'), 2097),\n",
       " (('g', '.'), 2092),\n",
       " (('k', 'n'), 2086),\n",
       " (('L', 'a'), 2071),\n",
       " (('1', '6'), 2071),\n",
       " (('H', 'i'), 2068),\n",
       " (('2', '<E>'), 2060),\n",
       " (('8', '8'), 2047),\n",
       " (('e', 'b'), 2044),\n",
       " (('o', 'k'), 2033),\n",
       " (('1', '5'), 2015),\n",
       " (('B', 'e'), 1999),\n",
       " (('.', ')'), 1997),\n",
       " (('m', ','), 1992),\n",
       " (('G', 'e'), 1942),\n",
       " ((')', ';'), 1937),\n",
       " (('n', 'v'), 1920),\n",
       " (('A', 'r'), 1920),\n",
       " (('o', 'e'), 1917),\n",
       " (('o', 'y'), 1913),\n",
       " (('a', '.'), 1908),\n",
       " (('l', 'p'), 1899),\n",
       " (('5', '<E>'), 1892),\n",
       " (('M', 'o'), 1889),\n",
       " (('e', 'u'), 1888),\n",
       " (('1', '0'), 1885),\n",
       " (('d', 'y'), 1877),\n",
       " (('B', 'a'), 1867),\n",
       " (('m', 'y'), 1863),\n",
       " (('r', 'b'), 1860),\n",
       " (('E', 'n'), 1851),\n",
       " (('g', ','), 1851),\n",
       " (('-', '1'), 1846),\n",
       " (('s', 'y'), 1831),\n",
       " (('<S>', 'q'), 1827),\n",
       " (('j', 'e'), 1813),\n",
       " (('r', 'p'), 1800),\n",
       " (('<S>', 'j'), 1770),\n",
       " (('P', 'o'), 1767),\n",
       " (('i', 'i'), 1752),\n",
       " (('<S>', '4'), 1717),\n",
       " (('1', '<E>'), 1716),\n",
       " (('8', '7'), 1705),\n",
       " (('e', '-'), 1697),\n",
       " (('S', 'a'), 1696),\n",
       " (('<S>', 'U'), 1679),\n",
       " (('L', 'o'), 1678),\n",
       " (('d', 'd'), 1665),\n",
       " (('A', 'f'), 1651),\n",
       " (('3', '<E>'), 1647),\n",
       " (('S', 'o'), 1640),\n",
       " (('A', 'b'), 1623),\n",
       " (('0', ','), 1618),\n",
       " (('A', 'c'), 1600),\n",
       " (('x', 'a'), 1597),\n",
       " (('s', ';'), 1596),\n",
       " (('n', 'k'), 1591),\n",
       " (('M', 'e'), 1570),\n",
       " (('y', 'l'), 1561),\n",
       " (('P', 'r'), 1560),\n",
       " (('N', 'o'), 1547),\n",
       " (('j', 'u'), 1541),\n",
       " (('i', 'k'), 1532),\n",
       " (('4', '<E>'), 1526),\n",
       " (('R', 'e'), 1517),\n",
       " (('8', '6'), 1512),\n",
       " (('x', 'c'), 1510),\n",
       " (('l', 'm'), 1504),\n",
       " (('D', 'e'), 1497),\n",
       " (('P', 'e'), 1495),\n",
       " (('B', 'u'), 1479),\n",
       " (('d', 'l'), 1463),\n",
       " (('d', 'g'), 1442),\n",
       " (('H', 'a'), 1440),\n",
       " (('l', 'b'), 1439),\n",
       " (('p', '.'), 1438),\n",
       " (('l', 'v'), 1437),\n",
       " (('a', 'h'), 1437),\n",
       " (('<S>', '5'), 1432),\n",
       " (('6', '<E>'), 1431),\n",
       " (('w', 'r'), 1425),\n",
       " (('8', '<E>'), 1413),\n",
       " (('c', 'y'), 1404),\n",
       " (('o', ','), 1402),\n",
       " (('y', 'a'), 1395),\n",
       " (('A', '<E>'), 1385),\n",
       " (('h', '.'), 1366),\n",
       " (('1', '1'), 1363),\n",
       " (('B', 'o'), 1344),\n",
       " (('7', '<E>'), 1339),\n",
       " (('c', '.'), 1331),\n",
       " (('8', '5'), 1330),\n",
       " (('k', 'a'), 1328),\n",
       " (('S', 'i'), 1324),\n",
       " (('I', '.'), 1318),\n",
       " (('1', '2'), 1311),\n",
       " (('w', 's'), 1307),\n",
       " (('d', 'm'), 1306),\n",
       " (('g', 'y'), 1299),\n",
       " (('i', 'x'), 1294),\n",
       " (('9', '<E>'), 1276),\n",
       " (('S', '.'), 1253),\n",
       " (('L', 'e'), 1243),\n",
       " ((',', \"'\"), 1232),\n",
       " (('S', 'c'), 1229),\n",
       " (('1', '4'), 1228),\n",
       " (('A', '.'), 1227),\n",
       " (('r', 'f'), 1221),\n",
       " (('h', 'l'), 1219),\n",
       " (('I', 'I'), 1218),\n",
       " (('C', '.'), 1209),\n",
       " (('z', 'a'), 1209),\n",
       " (('e', 'k'), 1205),\n",
       " (('N', 'e'), 1197),\n",
       " (('o', 'h'), 1191),\n",
       " (('b', 'j'), 1189),\n",
       " (('s', 'k'), 1184),\n",
       " (('8', '0'), 1181),\n",
       " (('y', 'i'), 1178),\n",
       " (('<S>', '6'), 1175),\n",
       " (('H', 'o'), 1169),\n",
       " ((',', '0'), 1158),\n",
       " (('L', 'i'), 1148),\n",
       " (('A', 't'), 1144),\n",
       " (('k', ','), 1143),\n",
       " (('8', '4'), 1143),\n",
       " (('b', 't'), 1140),\n",
       " (('u', '<E>'), 1125),\n",
       " (('O', 'n'), 1124),\n",
       " (('u', 'f'), 1121),\n",
       " (('y', 'p'), 1113),\n",
       " (('A', 's'), 1105),\n",
       " (('x', 'e'), 1103),\n",
       " (('5', '0'), 1103),\n",
       " (('8', '3'), 1100),\n",
       " (('e', ';'), 1099),\n",
       " (('l', 'c'), 1097),\n",
       " (('1', ','), 1092),\n",
       " (('1', '3'), 1087),\n",
       " (('J', 'o'), 1080),\n",
       " (('A', 'd'), 1080),\n",
       " (('y', 'o'), 1063),\n",
       " (('s', ')'), 1059),\n",
       " (('j', 'o'), 1057),\n",
       " (('F', 'o'), 1055),\n",
       " (('J', 'u'), 1053),\n",
       " (('r', '-'), 1052),\n",
       " (('v', '.'), 1046),\n",
       " (('n', 'm'), 1040),\n",
       " (('l', 'g'), 1040),\n",
       " (('2', ')'), 1039),\n",
       " (('d', 'v'), 1036),\n",
       " (('1', ')'), 1034),\n",
       " (('2', ','), 1028),\n",
       " (('0', ')'), 1028),\n",
       " (('W', 'i'), 1023),\n",
       " (('U', 'n'), 1017),\n",
       " (('y', 'm'), 1013),\n",
       " (('t', 'm'), 1012),\n",
       " (('S', 'p'), 1005),\n",
       " (('z', 'i'), 1004),\n",
       " (('M', 'i'), 1003),\n",
       " (('t', '-'), 1001),\n",
       " (('2', '0'), 987),\n",
       " (('A', 'L'), 968),\n",
       " (('E', '.'), 967),\n",
       " (('D', 'i'), 965),\n",
       " (('8', '1'), 947),\n",
       " (('W', 'a'), 946),\n",
       " (('<S>', '7'), 945),\n",
       " (('8', '2'), 943),\n",
       " (('y', 'r'), 941),\n",
       " (('W', 'e'), 938),\n",
       " (('l', 'k'), 933),\n",
       " (('r', 'w'), 931),\n",
       " (('x', '<E>'), 926),\n",
       " (('E', 'u'), 925),\n",
       " (('N', 'a'), 924),\n",
       " (('.', \"'\"), 921),\n",
       " (('i', ','), 917),\n",
       " (('5', ','), 908),\n",
       " (('t', 'c'), 908),\n",
       " (('T', 'o'), 905),\n",
       " (('W', '.'), 897),\n",
       " (('<S>', '8'), 896),\n",
       " (('h', 'n'), 895),\n",
       " (('s', \"'\"), 894),\n",
       " (('b', 'b'), 893),\n",
       " (('3', ','), 884),\n",
       " (('o', 'x'), 883),\n",
       " (('8', ','), 879),\n",
       " (('A', 'N'), 877),\n",
       " (('3', '0'), 875),\n",
       " (('4', ','), 868),\n",
       " (('n', \"'\"), 868),\n",
       " (('-', '<E>'), 866),\n",
       " (('0', '.'), 866),\n",
       " (('n', '-'), 859),\n",
       " (('V', 'i'), 858),\n",
       " (('J', 'a'), 857),\n",
       " (('r', \"'\"), 855),\n",
       " (('3', ')'), 852),\n",
       " (('l', 'w'), 851),\n",
       " (('e', 'h'), 845),\n",
       " (('S', 'u'), 841),\n",
       " (('A', 'u'), 840),\n",
       " (('W', 'h'), 840),\n",
       " (('o', '-'), 839),\n",
       " (('h', 'm'), 839),\n",
       " (('y', 'd'), 835),\n",
       " (('7', ','), 828),\n",
       " (('i', 'q'), 828),\n",
       " (('c', 's'), 827),\n",
       " (('9', ','), 824),\n",
       " (('d', '-'), 824),\n",
       " (('a', 'x'), 824),\n",
       " ((':', '<E>'), 822),\n",
       " (('a', 'z'), 822),\n",
       " (('.', '-'), 819),\n",
       " (('h', '-'), 819),\n",
       " (('S', 'h'), 818),\n",
       " (('h', 's'), 817),\n",
       " (('4', ')'), 815),\n",
       " (('l', '-'), 814),\n",
       " (('P', 'h'), 813),\n",
       " (('T', 'r'), 810),\n",
       " (('G', 'a'), 809),\n",
       " (('-', 'c'), 809),\n",
       " (('-', 's'), 807),\n",
       " (('z', 'o'), 804),\n",
       " (('6', '0'), 802),\n",
       " (('<S>', 'Y'), 797),\n",
       " (('<S>', 'x'), 790),\n",
       " (('D', 'a'), 789),\n",
       " (('g', 'g'), 788),\n",
       " (('y', 'n'), 788),\n",
       " (('7', '0'), 775),\n",
       " (('e', \"'\"), 772),\n",
       " (('4', '0'), 771),\n",
       " (('A', 'g'), 768),\n",
       " (('r', 'h'), 766),\n",
       " (('G', 'o'), 763),\n",
       " (('5', ')'), 757),\n",
       " (('s', 'b'), 754),\n",
       " (('B', '.'), 751),\n",
       " (('6', ')'), 748),\n",
       " (('d', \"'\"), 748),\n",
       " (('e', ')'), 747),\n",
       " (('.', 'C'), 744),\n",
       " (('-', 'a'), 744),\n",
       " (('6', ','), 741),\n",
       " (('7', '8'), 738),\n",
       " (('g', 't'), 736),\n",
       " (('-', 't'), 735),\n",
       " (('T', 'a'), 731),\n",
       " (('7', '9'), 725),\n",
       " (('R', 'u'), 717),\n",
       " (('<S>', '9'), 716),\n",
       " (('u', 'o'), 710),\n",
       " (('7', ')'), 702),\n",
       " (('V', 'a'), 698),\n",
       " (('M', 'u'), 693),\n",
       " (('a', '-'), 692),\n",
       " (('n', ';'), 684),\n",
       " (('F', 'e'), 684),\n",
       " (('s', 'f'), 683),\n",
       " (('J', '.'), 682),\n",
       " (('8', ')'), 681),\n",
       " (('-', 'p'), 681),\n",
       " (('9', ')'), 680),\n",
       " (('T', 'e'), 679),\n",
       " (('<S>', 'Z'), 677),\n",
       " (('q', '.'), 674),\n",
       " (('D', 'u'), 674),\n",
       " (('K', 'a'), 674),\n",
       " (('n', 'h'), 671),\n",
       " (('y', '-'), 670),\n",
       " (('C', 'l'), 669),\n",
       " (('w', 'l'), 669),\n",
       " (('s', 'q'), 662),\n",
       " (('7', '5'), 661),\n",
       " (('<S>', '&'), 658),\n",
       " (('7', '7'), 658),\n",
       " (('y', 't'), 655),\n",
       " (('2', '5'), 654),\n",
       " (('N', '.'), 653),\n",
       " (('0', '5'), 643),\n",
       " (('(', 's'), 642),\n",
       " (('C', 'r'), 637),\n",
       " (('-', 'w'), 636),\n",
       " (('T', 'u'), 634),\n",
       " (('-', 'e'), 629),\n",
       " (('m', 'n'), 625),\n",
       " (('2', '.'), 623),\n",
       " (('F', '.'), 622),\n",
       " (('N', 'i'), 620),\n",
       " (('J', 'e'), 620),\n",
       " (('H', '.'), 618),\n",
       " (('R', 'a'), 617),\n",
       " (('O', 'r'), 617),\n",
       " (('E', 'a'), 614),\n",
       " (('G', 'u'), 608),\n",
       " (('d', ';'), 605),\n",
       " (('0', '1'), 602),\n",
       " (('2', '4'), 597),\n",
       " (('I', 's'), 595),\n",
       " (('g', 'm'), 594),\n",
       " (('u', 'k'), 590),\n",
       " (('L', '.'), 588),\n",
       " (('2', '1'), 584),\n",
       " (('(', 'S'), 582),\n",
       " (('V', 'e'), 582),\n",
       " (('f', '.'), 580),\n",
       " (('1', '.'), 580),\n",
       " (('K', 'i'), 580),\n",
       " (('G', '.'), 578),\n",
       " (('w', ','), 577),\n",
       " (('2', '2'), 577),\n",
       " (('P', 'i'), 576),\n",
       " (('A', 'e'), 575),\n",
       " (('s', '-'), 573),\n",
       " (('n', 'q'), 569),\n",
       " (('n', 'j'), 567),\n",
       " (('D', 'o'), 564),\n",
       " (('y', 'c'), 561),\n",
       " (('E', 'R'), 561),\n",
       " (('D', '.'), 561),\n",
       " (('C', 'H'), 561),\n",
       " (('7', '6'), 559),\n",
       " (('l', \"'\"), 557),\n",
       " (('-', 'l'), 555),\n",
       " (('&', 'c'), 554),\n",
       " (('(', 'L'), 553),\n",
       " (('y', ';'), 553),\n",
       " (('(', 'a'), 551),\n",
       " (('6', '1'), 548),\n",
       " (('R', '.'), 545),\n",
       " (('F', 'i'), 544),\n",
       " (('2', '8'), 543),\n",
       " (('B', 'i'), 543),\n",
       " (('o', '.'), 542),\n",
       " (('O', 'N'), 541),\n",
       " (('A', 'p'), 541),\n",
       " (('F', 'a'), 538),\n",
       " (('n', 'b'), 537),\n",
       " (('n', 'z'), 535),\n",
       " (('(', 'A'), 535),\n",
       " (('3', '.'), 534),\n",
       " (('7', '1'), 533),\n",
       " (('7', '2'), 529),\n",
       " (('P', 'l'), 523),\n",
       " (('-', 'b'), 522),\n",
       " (('s', 'w'), 522),\n",
       " (('6', '8'), 519),\n",
       " (('2', '6'), 518),\n",
       " (('a', ')'), 517),\n",
       " (('n', ')'), 517),\n",
       " (('9', '9'), 515),\n",
       " (('3', '5'), 515),\n",
       " (('4', '8'), 514),\n",
       " (('3', '1'), 514),\n",
       " (('2', '3'), 512),\n",
       " (('5', '5'), 511),\n",
       " (('0', '2'), 511),\n",
       " (('c', ','), 510),\n",
       " (('s', 'n'), 510),\n",
       " (('C', 'e'), 510),\n",
       " (('t', 'z'), 509),\n",
       " (('-', 'f'), 507),\n",
       " (('b', '<E>'), 507),\n",
       " (('t', ';'), 506),\n",
       " (('0', '6'), 505),\n",
       " (('6', '2'), 501),\n",
       " (('6', '3'), 499),\n",
       " (('t', \"'\"), 497),\n",
       " (('n', 'r'), 496),\n",
       " (('E', 'l'), 496),\n",
       " (('6', '5'), 496),\n",
       " (('5', '2'), 493),\n",
       " (('f', ','), 492),\n",
       " (('2', '7'), 492),\n",
       " (('T', 'i'), 491),\n",
       " (('6', '7'), 491),\n",
       " (('l', 'r'), 490),\n",
       " (('M', '.'), 490),\n",
       " (('5', '.'), 488),\n",
       " (('0', '4'), 487),\n",
       " (('k', '.'), 486),\n",
       " (('9', '5'), 484),\n",
       " (('2', '9'), 484),\n",
       " (('7', '4'), 481),\n",
       " (('(', '2'), 480),\n",
       " (('6', '6'), 479),\n",
       " (('9', '2'), 477),\n",
       " (('R', 'i'), 476),\n",
       " (('p', 'y'), 474),\n",
       " (('6', '4'), 473),\n",
       " (('9', '7'), 472),\n",
       " (('9', '8'), 471),\n",
       " (('0', '3'), 471),\n",
       " (('3', '3'), 471),\n",
       " (('5', '1'), 470),\n",
       " (('E', 'g'), 469),\n",
       " (('5', '4'), 469),\n",
       " (('g', '-'), 466),\n",
       " (('4', '.'), 464),\n",
       " (('9', '4'), 464),\n",
       " (('5', '8'), 464),\n",
       " (('9', '1'), 462),\n",
       " (('9', '6'), 462),\n",
       " (('3', '2'), 460),\n",
       " (('-', 'g'), 459),\n",
       " (('E', 'd'), 459),\n",
       " (('p', ','), 458),\n",
       " (('H', 'u'), 457),\n",
       " (('5', '6'), 456),\n",
       " (('<S>', '-'), 454),\n",
       " (('5', '3'), 453),\n",
       " (('(', 'P'), 453),\n",
       " (('<S>', 'z'), 452),\n",
       " (('x', 'x'), 452),\n",
       " (('R', 'I'), 450),\n",
       " (('7', '3'), 450),\n",
       " (('3', '4'), 449),\n",
       " (('j', 'a'), 449),\n",
       " (('E', 'S'), 446),\n",
       " (('(', 'C'), 446),\n",
       " (('4', '5'), 445),\n",
       " (('6', '9'), 444),\n",
       " (('a', 'j'), 443),\n",
       " (('C', 'i'), 443),\n",
       " (('g', 'd'), 442),\n",
       " (('A', 'M'), 442),\n",
       " (('`', 'a'), 440),\n",
       " (('.', ';'), 440),\n",
       " (('B', 'y'), 440),\n",
       " (('T', 'I'), 439),\n",
       " (('5', '7'), 439),\n",
       " (('9', '3'), 436),\n",
       " ((',', '6'), 435),\n",
       " (('3', '8'), 432),\n",
       " (('A', 'R'), 431),\n",
       " (('S', '<E>'), 428),\n",
       " (('4', '9'), 428),\n",
       " (('r', ';'), 424),\n",
       " ((',', '5'), 423),\n",
       " (('O', 'f'), 421),\n",
       " (('4', '2'), 419),\n",
       " (('6', '.'), 419),\n",
       " (('F', 'l'), 418),\n",
       " (('3', '6'), 416),\n",
       " (('-', 'h'), 415),\n",
       " (('4', '7'), 415),\n",
       " (('(', 'f'), 413),\n",
       " (('y', \"'\"), 413),\n",
       " (('.', 'v'), 412),\n",
       " (('4', '1'), 411),\n",
       " (('z', '<E>'), 411),\n",
       " ((',', '2'), 409),\n",
       " ((',', '3'), 408),\n",
       " (('0', '7'), 407),\n",
       " ((',', '4'), 407),\n",
       " (('h', 'b'), 407),\n",
       " (('4', '3'), 407),\n",
       " (('e', 'z'), 406),\n",
       " (('5', '9'), 405),\n",
       " (('L', 'u'), 404),\n",
       " (('-', 'm'), 404),\n",
       " ((',', '1'), 404),\n",
       " (('R', 'A'), 398),\n",
       " (('8', '.'), 398),\n",
       " (('d', 'w'), 398),\n",
       " (('n', 'w'), 397),\n",
       " (('V', '.'), 396),\n",
       " (('3', '7'), 394),\n",
       " (('9', '.'), 392),\n",
       " (('b', 'd'), 391),\n",
       " ((',', '7'), 388),\n",
       " (('A', 'B'), 387),\n",
       " (('3', '9'), 387),\n",
       " (('E', 'N'), 386),\n",
       " (('<S>', 'X'), 386),\n",
       " (('`', 'A'), 386),\n",
       " (('4', '4'), 384),\n",
       " (('C', 'O'), 383),\n",
       " (('7', '.'), 381),\n",
       " (('P', '.'), 378),\n",
       " ((',', '8'), 377),\n",
       " ((\"'\", 'A'), 377),\n",
       " (('4', '6'), 376),\n",
       " (('L', 'E'), 375),\n",
       " (('x', '.'), 375),\n",
       " (('(', 'q'), 375),\n",
       " (('<S>', '|'), 375),\n",
       " (('<S>', 'Q'), 374),\n",
       " (('`', 't'), 372),\n",
       " (('(', 'c'), 370),\n",
       " (('E', 't'), 368),\n",
       " ((',', '9'), 368),\n",
       " (('0', '-'), 367),\n",
       " (('E', '<E>'), 365),\n",
       " (('A', 'i'), 363),\n",
       " (('(', 'i'), 360),\n",
       " (('k', 'o'), 360),\n",
       " (('D', 'r'), 359),\n",
       " (('|', '<E>'), 359),\n",
       " (('h', 'w'), 357),\n",
       " (('Y', 'o'), 356),\n",
       " (('(', 'B'), 355),\n",
       " (('N', '<E>'), 351),\n",
       " (('v', 'y'), 345),\n",
       " (('-', 'd'), 344),\n",
       " (('O', 'c'), 343),\n",
       " (('-', 'T'), 342),\n",
       " (('(', 't'), 340),\n",
       " (('I', 'N'), 338),\n",
       " (('Q', 'u'), 336),\n",
       " (('-', 'i'), 336),\n",
       " (('A', 'E'), 333),\n",
       " (('L', 'I'), 331),\n",
       " (('-', 'o'), 331),\n",
       " (('p', 'm'), 329),\n",
       " (('0', '8'), 329),\n",
       " (('.', '8'), 329),\n",
       " (('.', 'D'), 328),\n",
       " (('.', '9'), 327),\n",
       " (('(', '3'), 327),\n",
       " (('u', ','), 324),\n",
       " (('P', 'u'), 323),\n",
       " (('E', 'x'), 321),\n",
       " (('5', 't'), 321),\n",
       " (('a', ';'), 320),\n",
       " (('w', '.'), 319),\n",
       " (('8', 't'), 319),\n",
       " (('G', 'l'), 319),\n",
       " (('4', 't'), 318),\n",
       " (('6', 't'), 318),\n",
       " (('c', 'q'), 318),\n",
       " (('A', 'C'), 315),\n",
       " (('b', '.'), 315),\n",
       " (('S', 'w'), 314),\n",
       " (('9', 't'), 314),\n",
       " (('0', '9'), 314),\n",
       " (('W', 'o'), 312),\n",
       " (('k', 'l'), 312),\n",
       " (('f', 's'), 311),\n",
       " (('o', 'j'), 309),\n",
       " (('I', 'r'), 308),\n",
       " (('-', 'A'), 308),\n",
       " (('a', 'o'), 307),\n",
       " (('u', 'x'), 306),\n",
       " (('R', 'E'), 304),\n",
       " (('s', ':'), 304),\n",
       " (('A', 'T'), 303),\n",
       " (('O', 'R'), 301),\n",
       " (('N', 'D'), 301),\n",
       " (('r', ')'), 300),\n",
       " (('s', 'd'), 298),\n",
       " (('S', ','), 298),\n",
       " (('T', 'H'), 297),\n",
       " (('x', 'h'), 297),\n",
       " (('k', 'h'), 297),\n",
       " (('%', '<E>'), 297),\n",
       " (('A', 'D'), 296),\n",
       " (('V', 'I'), 295),\n",
       " (('M', 'A'), 293),\n",
       " (('(', 'M'), 289),\n",
       " (('t', ')'), 288),\n",
       " (('B', 'l'), 288),\n",
       " (('K', 'e'), 287),\n",
       " (('I', 'A'), 286),\n",
       " (('y', ')'), 286),\n",
       " (('G', 'i'), 286),\n",
       " (('C', 'u'), 285),\n",
       " (('I', 'S'), 285),\n",
       " (('T', '.'), 285),\n",
       " (('u', 'v'), 285),\n",
       " (('D', 'E'), 284),\n",
       " (('S', 'y'), 284),\n",
       " (('I', 'f'), 283),\n",
       " (('w', 't'), 283),\n",
       " (('t', 'n'), 283),\n",
       " (('U', 'S'), 281),\n",
       " (('K', 'o'), 280),\n",
       " (('Z', 'e'), 280),\n",
       " (('<S>', '\"'), 279),\n",
       " (('7', 't'), 278),\n",
       " (('x', 'v'), 278),\n",
       " (('f', 'g'), 278),\n",
       " (('x', ','), 276),\n",
       " (('1', '/'), 275),\n",
       " (('a', 'a'), 273),\n",
       " (('I', 'T'), 273),\n",
       " (('\"', '<E>'), 273),\n",
       " (('H', 'O'), 271),\n",
       " (('d', 'h'), 270),\n",
       " (('I', 'C'), 265),\n",
       " (('_', '_'), 262),\n",
       " ((\"'\", ')'), 261),\n",
       " (('(', 'o'), 259),\n",
       " (('O', '<E>'), 259),\n",
       " (('O', 'l'), 259),\n",
       " (('N', ','), 258),\n",
       " (('1', '-'), 256),\n",
       " (('E', 'v'), 256),\n",
       " (('T', 'E'), 254),\n",
       " (('d', 't'), 254),\n",
       " (('d', ')'), 253),\n",
       " (('l', 'n'), 253),\n",
       " (('S', 'T'), 252),\n",
       " (('x', 'u'), 252),\n",
       " (('I', 'O'), 252),\n",
       " (('H', '2'), 252),\n",
       " (('(', 'G'), 251),\n",
       " (('8', '-'), 250),\n",
       " (('.', 'S'), 250),\n",
       " (('F', 'u'), 250),\n",
       " (('-', 'r'), 249),\n",
       " (('<S>', '0'), 249),\n",
       " (('.', '7'), 249),\n",
       " ((':', '-'), 248),\n",
       " (('6', '-'), 248),\n",
       " (('5', '-'), 247),\n",
       " (('k', 'y'), 247),\n",
       " (('M', 'E'), 246),\n",
       " (('2', 'n'), 246),\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key = lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "615a8e9f-972b-43c8-925e-9319abaa3ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5571b8e-c475-4cec-8858-908e2a1afd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37922e47-9893-4cde-91c0-701884971f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec75de1-eb94-435c-9c06-f44f7f4ebab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 53 is out of bounds for dimension 1 with size 27",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m ix1 \u001b[38;5;241m=\u001b[39m stoi[ch1]\n\u001b[0;32m      5\u001b[0m ix2 \u001b[38;5;241m=\u001b[39m stoi[ch2]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mN\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mix2\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 53 is out of bounds for dimension 1 with size 27"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128ad93-261a-474d-9890-0b9020a91c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b3c347-38e4-4124-bf3c-5e5e806b49ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6785d5fa-e68d-411c-8068-0976a669d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7974ce47-137a-4260-879d-20e7b8e3de5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25bc5c42-5906-4b50-8bf5-dfd50a6f6473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6064, 0.3033, 0.0903])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2451918d-5fd3-4383-93bb-460a135faf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0,\n",
       "        0, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a12af8-782d-4991-a1bc-fb11f9918bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4a6e70-7225-4f71-9b70-502c0b6b083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolian.\n",
      "juee.\n",
      "ksahnaauranilevias.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "\n",
    "        p = P[ix]\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d941e95-70dc-473e-bb51-30dad57bb208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood=tensor(-559951.5625)\n",
      "nll=tensor(559951.5625)\n",
      "2.4543561935424805\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "\n",
    "print(f'{log_likelihood=}')\n",
    "nll =-log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64137854-4f5e-49d1-b211-8a9792079783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n"
     ]
    }
   ],
   "source": [
    "# create the training set of bigrams\n",
    "\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "382cb1c4-8228-4a69-8f86-9034210333b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19aa76d4-35fc-4a96-9829-f9d49bf1f755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "290388cf-21d0-40ea-9f31-b25c40ec6fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f097d5-f8f5-453c-879d-3d5c6c663aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97337fb5-2433-4f2e-b587-70578932d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x260a982b170>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5e4062a-a807-4b57-9a5e-1466e03ea664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73de0ba9-6dbf-4a57-82f6-141dccfb76bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6637,  0.6988, -1.0531,  0.9577,  0.2033,  0.8734, -1.9746,  0.6182,\n",
       "          1.0045,  0.0851, -0.1080, -0.0831,  0.4002,  0.7908, -0.7154, -1.0015,\n",
       "          1.3535,  0.6259,  0.0634,  0.6938,  2.0649,  0.8386, -2.1347,  0.6641,\n",
       "          1.5818, -0.7462,  0.0635],\n",
       "        [ 1.2111, -0.1899,  0.7802, -0.4765,  1.6384, -1.0221, -0.7043, -0.2298,\n",
       "          1.7604, -1.2083,  1.8231,  0.7074, -0.8221,  0.2739,  0.8827, -1.8190,\n",
       "          0.1045,  0.0959, -0.3997,  0.1852, -1.2572,  0.8807,  1.0721,  0.1687,\n",
       "         -1.4620,  0.0996, -0.2310],\n",
       "        [-0.9603,  1.1569, -1.1104, -0.9368, -0.7341, -0.1664,  1.0834,  0.5795,\n",
       "         -0.3147, -0.0936,  0.3457,  0.7584, -0.1183,  0.8247, -0.6132,  1.8514,\n",
       "          1.2996, -1.1118, -1.2255, -0.2368,  2.7097,  1.5129, -0.6265, -1.7150,\n",
       "         -0.4451, -0.9345, -1.1119],\n",
       "        [-0.9603,  1.1569, -1.1104, -0.9368, -0.7341, -0.1664,  1.0834,  0.5795,\n",
       "         -0.3147, -0.0936,  0.3457,  0.7584, -0.1183,  0.8247, -0.6132,  1.8514,\n",
       "          1.2996, -1.1118, -1.2255, -0.2368,  2.7097,  1.5129, -0.6265, -1.7150,\n",
       "         -0.4451, -0.9345, -1.1119],\n",
       "        [-1.1832, -0.2501,  0.7172,  0.6081, -0.0379, -1.3433, -0.8618, -0.0487,\n",
       "          1.6458, -0.4167,  0.2026, -0.5917,  0.2834, -0.8106,  0.6882, -1.2790,\n",
       "         -1.0838,  0.3656, -0.4293,  1.0138,  0.2052, -0.7314, -0.2985,  1.3177,\n",
       "          0.0757, -0.3964, -2.1893]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27))\n",
    "xenc @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f83717f4-b560-4d1f-a618-c774a79b8a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0387, 0.0401, 0.0070, 0.0519, 0.0244, 0.0477, 0.0028, 0.0370, 0.0544,\n",
       "         0.0217, 0.0179, 0.0183, 0.0297, 0.0439, 0.0097, 0.0073, 0.0771, 0.0373,\n",
       "         0.0212, 0.0399, 0.1571, 0.0461, 0.0024, 0.0387, 0.0969, 0.0094, 0.0212],\n",
       "        [0.0738, 0.0182, 0.0480, 0.0137, 0.1132, 0.0079, 0.0109, 0.0175, 0.1279,\n",
       "         0.0066, 0.1362, 0.0446, 0.0097, 0.0289, 0.0532, 0.0036, 0.0244, 0.0242,\n",
       "         0.0147, 0.0265, 0.0063, 0.0531, 0.0643, 0.0260, 0.0051, 0.0243, 0.0175],\n",
       "        [0.0073, 0.0608, 0.0063, 0.0075, 0.0092, 0.0162, 0.0564, 0.0341, 0.0139,\n",
       "         0.0174, 0.0270, 0.0408, 0.0170, 0.0436, 0.0103, 0.1217, 0.0701, 0.0063,\n",
       "         0.0056, 0.0151, 0.2871, 0.0867, 0.0102, 0.0034, 0.0122, 0.0075, 0.0063],\n",
       "        [0.0073, 0.0608, 0.0063, 0.0075, 0.0092, 0.0162, 0.0564, 0.0341, 0.0139,\n",
       "         0.0174, 0.0270, 0.0408, 0.0170, 0.0436, 0.0103, 0.1217, 0.0701, 0.0063,\n",
       "         0.0056, 0.0151, 0.2871, 0.0867, 0.0102, 0.0034, 0.0122, 0.0075, 0.0063],\n",
       "        [0.0094, 0.0240, 0.0631, 0.0566, 0.0297, 0.0080, 0.0130, 0.0293, 0.1597,\n",
       "         0.0203, 0.0377, 0.0170, 0.0409, 0.0137, 0.0613, 0.0086, 0.0104, 0.0444,\n",
       "         0.0200, 0.0849, 0.0378, 0.0148, 0.0229, 0.1150, 0.0332, 0.0207, 0.0034]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # equivalent N\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78563187-27b4-4a8a-8855-b6b564e514d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a06033dc-201c-41b4-ac63-c15e1137d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4962731e-e1d0-4649-8c96-8b13bcd5f528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1e8343c-325d-41be-99b1-fe7b6088d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "155f28a7-0c36-4969-8412-5ebaa58864a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "# btw: the last 2 lines here are together called a 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4572507d-ffc8-4f02-9fad-8dbc7e81dfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2078a7c-6342-4d66-9064-e9770cd12ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "bigram example 1: .e (indexes 0,5)\n",
      "input to the neural net: 0\n",
      "output probabilities from the neural net: tensor([0.0607, 0.0100, 0.0123, 0.0042, 0.0168, 0.0123, 0.0027, 0.0232, 0.0137,\n",
      "        0.0313, 0.0079, 0.0278, 0.0091, 0.0082, 0.0500, 0.2378, 0.0603, 0.0025,\n",
      "        0.0249, 0.0055, 0.0339, 0.0109, 0.0029, 0.0198, 0.0118, 0.1537, 0.1459])\n",
      "label (actual next character): 5\n",
      "probability assigned by the net to the correct character: 0.01228625513613224\n",
      "log likelihood: -4.399273872375488\n",
      "negative log likelihood: 4.399273872375488\n",
      "--------\n",
      "bigram example 2: em (indexes 5,13)\n",
      "input to the neural net: 5\n",
      "output probabilities from the neural net: tensor([0.0290, 0.0796, 0.0248, 0.0521, 0.1989, 0.0289, 0.0094, 0.0335, 0.0097,\n",
      "        0.0301, 0.0702, 0.0228, 0.0115, 0.0181, 0.0108, 0.0315, 0.0291, 0.0045,\n",
      "        0.0916, 0.0215, 0.0486, 0.0300, 0.0501, 0.0027, 0.0118, 0.0022, 0.0472])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the correct character: 0.018050700426101685\n",
      "log likelihood: -4.014570713043213\n",
      "negative log likelihood: 4.014570713043213\n",
      "--------\n",
      "bigram example 3: mm (indexes 13,13)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 13\n",
      "probability assigned by the net to the correct character: 0.026691533625125885\n",
      "log likelihood: -3.623408794403076\n",
      "negative log likelihood: 3.623408794403076\n",
      "--------\n",
      "bigram example 4: ma (indexes 13,1)\n",
      "input to the neural net: 13\n",
      "output probabilities from the neural net: tensor([0.0312, 0.0737, 0.0484, 0.0333, 0.0674, 0.0200, 0.0263, 0.0249, 0.1226,\n",
      "        0.0164, 0.0075, 0.0789, 0.0131, 0.0267, 0.0147, 0.0112, 0.0585, 0.0121,\n",
      "        0.0650, 0.0058, 0.0208, 0.0078, 0.0133, 0.0203, 0.1204, 0.0469, 0.0126])\n",
      "label (actual next character): 1\n",
      "probability assigned by the net to the correct character: 0.07367686182260513\n",
      "log likelihood: -2.6080665588378906\n",
      "negative log likelihood: 2.6080665588378906\n",
      "--------\n",
      "bigram example 5: a. (indexes 1,0)\n",
      "input to the neural net: 1\n",
      "output probabilities from the neural net: tensor([0.0150, 0.0086, 0.0396, 0.0100, 0.0606, 0.0308, 0.1084, 0.0131, 0.0125,\n",
      "        0.0048, 0.1024, 0.0086, 0.0988, 0.0112, 0.0232, 0.0207, 0.0408, 0.0078,\n",
      "        0.0899, 0.0531, 0.0463, 0.0309, 0.0051, 0.0329, 0.0654, 0.0503, 0.0091])\n",
      "label (actual next character): 0\n",
      "probability assigned by the net to the correct character: 0.014977526850998402\n",
      "log likelihood: -4.201204299926758\n",
      "negative log likelihood: 4.201204299926758\n",
      "=========\n",
      "average negative log likelihood, i.e. loss = 3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    # i-th bigram:\n",
    "    x = xs[i].item() # input character index\n",
    "    y = ys[i].item() # label character index\n",
    "    print('--------')\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "    print('input to the neural net:', x)\n",
    "    print('output probabilities from the neural net:', probs[i])\n",
    "    print('label (actual next character):', y)\n",
    "    p = probs[i, y]\n",
    "    print('probability assigned by the net to the correct character:', p.item())\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood:', logp.item())\n",
    "    nll = -logp\n",
    "    print('negative log likelihood:', nll.item())\n",
    "    nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9947a346-2061-4eda-a38f-4121038c469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d695dbc-8ddb-495b-a757-cdf75943fcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a4e05dd-3fbe-413c-837d-eda95acc7bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0977270-3a9b-4f6b-a1f3-418e02328813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac49666b-e13c-4bf5-8502-ef9b064d0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(5), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af38afc3-46d9-4f55-9414-26dfbfec9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7693049907684326\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df722e26-0a2f-4e10-a92f-9509b9915bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set to zero the gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48a931f0-6009-4951-bdb1-c2b0f7ac60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "babcf7be-52a0-45b6-bdd3-b5c07e4b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "len(words)\n",
    "train_set = []\n",
    "dev_set = []\n",
    "test_set = []\n",
    "for w in words:\n",
    "    n = random.randrange(1, 10, 1)\n",
    "    if n < 8:\n",
    "        train_set.append(w)\n",
    "    elif n == 9:\n",
    "        dev_set.append(w)\n",
    "    else:\n",
    "        test_set.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5412ea-2a83-4e28-9657-5eef5106b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049232"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12462c2-930f-4650-aa67-970024319c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149854"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_set)\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3ebea3d-b624-485c-abac-f3472a6bd65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- OPTIMIZATION and WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a303ae-15f3-4988-8bb4-b0cc2cce521e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stoi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m chs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m (w) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ch1, ch2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(chs, chs[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m----> 6\u001b[0m     ix1 \u001b[38;5;241m=\u001b[39m \u001b[43mstoi\u001b[49m[ch1]\n\u001b[0;32m      7\u001b[0m     ix2 \u001b[38;5;241m=\u001b[39m stoi[ch2]\n\u001b[0;32m      8\u001b[0m     xs\u001b[38;5;241m.\u001b[39mappend(ix1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stoi' is not defined"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in train_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bf9462cf-22c3-4a25-bbe3-1a6fc6eb22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.765869379043579\n",
      "2.7646641731262207\n",
      "2.763479709625244\n",
      "2.762315034866333\n",
      "2.761169195175171\n",
      "2.7600419521331787\n",
      "2.7589335441589355\n",
      "2.757842540740967\n",
      "2.7567684650421143\n",
      "2.755711555480957\n",
      "2.7546703815460205\n",
      "2.753645181655884\n",
      "2.7526350021362305\n",
      "2.7516403198242188\n",
      "2.7506601810455322\n",
      "2.7496938705444336\n",
      "2.7487411499023438\n",
      "2.747802257537842\n",
      "2.7468760013580322\n",
      "2.7459630966186523\n",
      "2.7450618743896484\n",
      "2.744173049926758\n",
      "2.743295669555664\n",
      "2.7424302101135254\n",
      "2.7415754795074463\n",
      "2.740732192993164\n",
      "2.739898920059204\n",
      "2.7390758991241455\n",
      "2.7382636070251465\n",
      "2.7374608516693115\n",
      "2.7366678714752197\n",
      "2.735883951187134\n",
      "2.735109329223633\n",
      "2.7343437671661377\n",
      "2.7335867881774902\n",
      "2.7328386306762695\n",
      "2.732098340988159\n",
      "2.7313663959503174\n",
      "2.730642557144165\n",
      "2.729926109313965\n",
      "2.729217767715454\n",
      "2.7285165786743164\n",
      "2.7278225421905518\n",
      "2.7271361351013184\n",
      "2.7264561653137207\n",
      "2.725783348083496\n",
      "2.725116729736328\n",
      "2.724457263946533\n",
      "2.723803758621216\n",
      "2.723156690597534\n",
      "2.722515821456909\n",
      "2.7218809127807617\n",
      "2.7212517261505127\n",
      "2.720628499984741\n",
      "2.720010995864868\n",
      "2.7193989753723145\n",
      "2.718791961669922\n",
      "2.718190908432007\n",
      "2.717594861984253\n",
      "2.7170042991638184\n",
      "2.7164182662963867\n",
      "2.7158374786376953\n",
      "2.715261459350586\n",
      "2.7146904468536377\n",
      "2.714123487472534\n",
      "2.713561773300171\n",
      "2.7130041122436523\n",
      "2.712451219558716\n",
      "2.7119028568267822\n",
      "2.7113585472106934\n",
      "2.710818290710449\n",
      "2.710282325744629\n",
      "2.7097508907318115\n",
      "2.7092227935791016\n",
      "2.7086989879608154\n",
      "2.708179235458374\n",
      "2.707663059234619\n",
      "2.707150459289551\n",
      "2.706641912460327\n",
      "2.70613694190979\n",
      "2.7056353092193604\n",
      "2.7051377296447754\n",
      "2.704643487930298\n",
      "2.7041523456573486\n",
      "2.703664541244507\n",
      "2.7031803131103516\n",
      "2.7026994228363037\n",
      "2.7022218704223633\n",
      "2.701747179031372\n",
      "2.7012758255004883\n",
      "2.7008073329925537\n",
      "2.7003421783447266\n",
      "2.6998798847198486\n",
      "2.69942045211792\n",
      "2.6989643573760986\n",
      "2.6985111236572266\n",
      "2.6980602741241455\n",
      "2.6976125240325928\n",
      "2.69716739654541\n",
      "2.696725368499756\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits**2 # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57acd138-5685-4245-99f5-a82e239e3049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kuwididiay.\n",
      "kariay.\n",
      "kay.\n",
      "kariale.\n",
      "riltole.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76893464-37dd-4af5-a4d9-dc12a2f26b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over dev set:  2.4694085121154785\n"
     ]
    }
   ],
   "source": [
    "# Dev set\n",
    "xs, ys = [], []\n",
    "for w in dev_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(len(xs)), ys].log().mean()\n",
    "print(\"Loss over dev set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bf7f890-f0ed-4c95-993c-fe8290404a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over test set:  2.472609281539917\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "xs, ys = [], []\n",
    "for w in test_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(len(xs)), ys].log().mean()\n",
    "print(\"Loss over test set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9bb55c07-1161-4ad4-bae7-0073e2f40c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples 152165\n"
     ]
    }
   ],
   "source": [
    "# Trigram model\n",
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in train_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(\"examples\", ys.shape[0])\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((54, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd99eb43-aa52-4f4d-adb7-9d9c90043e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.186872482299805\n",
      "10 3.075575113296509\n",
      "20 2.7854020595550537\n",
      "30 2.6502180099487305\n",
      "40 2.5669429302215576\n",
      "50 2.5102450847625732\n",
      "60 2.469637155532837\n",
      "70 2.439359188079834\n",
      "80 2.4159204959869385\n",
      "90 2.3971877098083496\n",
      "100 2.381840705871582\n",
      "110 2.3690271377563477\n",
      "120 2.3581671714782715\n",
      "130 2.3488502502441406\n",
      "140 2.3407742977142334\n",
      "150 2.3337135314941406\n",
      "160 2.327493190765381\n",
      "170 2.3219778537750244\n",
      "180 2.31705904006958\n",
      "190 2.3126487731933594\n",
      "200 2.30867600440979\n",
      "210 2.305081367492676\n",
      "220 2.301814556121826\n",
      "230 2.298835039138794\n",
      "240 2.296107053756714\n",
      "250 2.29360032081604\n",
      "260 2.2912895679473877\n",
      "270 2.2891528606414795\n",
      "280 2.2871711254119873\n",
      "290 2.2853281497955322\n",
      "300 2.283609628677368\n",
      "310 2.282003164291382\n",
      "320 2.280498504638672\n",
      "330 2.279085636138916\n",
      "340 2.2777562141418457\n",
      "350 2.276503324508667\n",
      "360 2.275320291519165\n",
      "370 2.2742011547088623\n",
      "380 2.2731409072875977\n",
      "390 2.272134780883789\n",
      "400 2.27117919921875\n",
      "410 2.2702698707580566\n",
      "420 2.2694032192230225\n",
      "430 2.2685768604278564\n",
      "440 2.2677879333496094\n",
      "450 2.2670340538024902\n",
      "460 2.266312599182129\n",
      "470 2.2656214237213135\n",
      "480 2.2649588584899902\n",
      "490 2.2643229961395264\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(500):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc.view(-1, 27*2) @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.001 * (W**2).mean()\n",
    "    if (k % 10 == 0):\n",
    "        print(k, loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c6544a5-90a0-4155-91f8-276d43242f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.1859025955200195\n",
      "10 3.0748207569122314\n",
      "20 2.784714698791504\n",
      "30 2.6495656967163086\n",
      "40 2.5663082599639893\n",
      "50 2.5096168518066406\n",
      "60 2.4690098762512207\n",
      "70 2.438729763031006\n",
      "80 2.4152865409851074\n",
      "90 2.396548271179199\n",
      "100 2.3811941146850586\n",
      "110 2.3683724403381348\n",
      "120 2.357504367828369\n",
      "130 2.3481781482696533\n",
      "140 2.3400933742523193\n",
      "150 2.3330230712890625\n",
      "160 2.3267934322357178\n",
      "170 2.3212685585021973\n",
      "180 2.3163399696350098\n",
      "190 2.3119208812713623\n",
      "200 2.307939052581787\n",
      "210 2.304335117340088\n",
      "220 2.3010594844818115\n",
      "230 2.2980713844299316\n",
      "240 2.2953343391418457\n",
      "250 2.2928194999694824\n",
      "260 2.2905006408691406\n",
      "270 2.288356065750122\n",
      "280 2.2863662242889404\n",
      "290 2.284515619277954\n",
      "300 2.282789707183838\n",
      "310 2.2811760902404785\n",
      "320 2.2796638011932373\n",
      "330 2.2782437801361084\n",
      "340 2.276907444000244\n",
      "350 2.2756476402282715\n",
      "360 2.2744576930999756\n",
      "370 2.273331880569458\n",
      "380 2.2722651958465576\n",
      "390 2.2712528705596924\n",
      "400 2.2702903747558594\n",
      "410 2.2693748474121094\n",
      "420 2.2685022354125977\n",
      "430 2.267669916152954\n",
      "440 2.2668745517730713\n",
      "450 2.2661147117614746\n",
      "460 2.265387535095215\n",
      "470 2.264690399169922\n",
      "480 2.2640221118927\n",
      "490 2.263380527496338\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(500):\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc.view(-1, 27*2) @ W # predict log-counts\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "    if (k % 10 == 0):\n",
    "        print(k, loss.item())\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -10 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63bdf691-25e3-4972-9a43-83f65cda109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aunide.\n",
      "aliasad.\n",
      "ushfay.\n",
      "ainn.\n",
      "aui.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    out = []\n",
    "    ix1, ix2 = 0, 0\n",
    "    while True:\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor((ix1, ix2)), num_classes=27).float()\n",
    "        logits = xenc.view(-1, 27*2) @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "        ix1 = ix2\n",
    "        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix2])\n",
    "        if ix2 == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d337331-5820-4178-8da1-be718b8b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over dev set:  2.26912784576416\n"
     ]
    }
   ],
   "source": [
    "# Dev set\n",
    "xs, ys = [], []\n",
    "for w in dev_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc.view(-1, 27*2) @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(len(xs)), ys].log().mean()\n",
    "print(\"Loss over dev set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3a0ef1c0-535d-43da-8255-b8805827bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over dev set:  2.2705719470977783\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "xs, ys = [], []\n",
    "for w in test_set:\n",
    "    chs = ['.'] + list (w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        xs.append((ix1,ix2))\n",
    "        ys.append(ix3)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc.view(-1, 27*2) @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(len(xs)), ys].log().mean()\n",
    "print(\"Loss over dev set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ba8d26-82ea-45b9-a90e-5029d2233da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6384ec00-3efc-43e7-af7c-54d878e44a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "\n",
    "words = open('Dataset/English/Encyclopedia.txt', 'r').read().split()\n",
    "\n",
    "c = len(words)\n",
    "\n",
    "train_set = words[:math.floor(c*0.8)]\n",
    "dev_set = words[math.floor(c*0.8):math.floor(c*0.9)]\n",
    "test_set = words[math.floor(c*0.9):]\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
    "stoi['<S>'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d2c721f-8097-4f08-84e2-d9eccf0e830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6429210]) torch.Size([6429210])\n",
      "torch.Size([815037]) torch.Size([815037])\n",
      "torch.Size([816603]) torch.Size([816603])\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        chs = ['<S>'] + list (w) + ['<S>']\n",
    "        for ch1, ch2 in zip(chs, chs[1:]):\n",
    "            ix1 = stoi[ch1]\n",
    "            ix2 = stoi[ch2]\n",
    "            X.append(ix1)\n",
    "            Y.append(ix2)\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "Xtr, Ytr = build_dataset(train_set)\n",
    "Xdev, Ydev = build_dataset(dev_set)\n",
    "Xte, Yte = build_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5421976b-c148-4018-bd9b-b214435b4cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((len(stoi), len(stoi)), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90486975-0d44-475b-817a-afeb2f9e9a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 0, time: -1741745873.06, total time: 0.03 seconds, steps/s: -0.00, examples/s: -0.00, total examples: 1024000, loss: 2.4448466300964355\n",
      "Steps: 1000, time: 1.66, total time: 1.69 seconds, steps/s: 601.32, examples/s: 615754.53, total examples: 2048000, loss: 2.5114712715148926\n",
      "Steps: 2000, time: 1.57, total time: 3.26 seconds, steps/s: 636.13, examples/s: 651398.59, total examples: 3072000, loss: 2.5475616455078125\n",
      "Steps: 3000, time: 1.54, total time: 4.81 seconds, steps/s: 648.29, examples/s: 663847.31, total examples: 4096000, loss: 2.408780336380005\n",
      "Steps: 4000, time: 1.55, total time: 6.36 seconds, steps/s: 643.50, examples/s: 658943.59, total examples: 5120000, loss: 2.5027709007263184\n",
      "Steps: 5000, time: 1.57, total time: 7.93 seconds, steps/s: 635.73, examples/s: 650986.48, total examples: 6144000, loss: 2.512439489364624\n",
      "Steps: 6000, time: 1.55, total time: 9.48 seconds, steps/s: 646.41, examples/s: 661926.03, total examples: 7168000, loss: 2.4820923805236816\n",
      "Steps: 7000, time: 1.57, total time: 11.05 seconds, steps/s: 637.75, examples/s: 653059.40, total examples: 8192000, loss: 2.482694625854492\n",
      "Steps: 8000, time: 1.59, total time: 12.64 seconds, steps/s: 629.72, examples/s: 644837.60, total examples: 9216000, loss: 2.467996835708618\n",
      "Steps: 9000, time: 1.56, total time: 14.19 seconds, steps/s: 642.67, examples/s: 658098.19, total examples: 10240000, loss: 2.494527578353882\n",
      "Steps: 10000, time: 1.55, total time: 15.74 seconds, steps/s: 646.41, examples/s: 661924.09, total examples: 11264000, loss: 2.5037124156951904\n",
      "Steps: 11000, time: 1.57, total time: 17.31 seconds, steps/s: 635.73, examples/s: 650986.38, total examples: 12288000, loss: 2.4599061012268066\n",
      "Steps: 12000, time: 1.55, total time: 18.87 seconds, steps/s: 643.50, examples/s: 658945.51, total examples: 13312000, loss: 2.519836664199829\n",
      "Steps: 13000, time: 1.54, total time: 20.40 seconds, steps/s: 651.46, examples/s: 667099.39, total examples: 14336000, loss: 2.46038556098938\n",
      "Steps: 14000, time: 1.59, total time: 21.99 seconds, steps/s: 630.91, examples/s: 646056.48, total examples: 15360000, loss: 2.435335397720337\n",
      "Steps: 15000, time: 1.53, total time: 23.52 seconds, steps/s: 653.17, examples/s: 668845.81, total examples: 16384000, loss: 2.5660436153411865\n",
      "Steps: 16000, time: 1.55, total time: 25.07 seconds, steps/s: 645.58, examples/s: 661071.14, total examples: 17408000, loss: 2.475113868713379\n",
      "Steps: 17000, time: 1.53, total time: 26.60 seconds, steps/s: 652.74, examples/s: 668406.97, total examples: 18432000, loss: 2.509204626083374\n",
      "Steps: 18000, time: 1.56, total time: 28.15 seconds, steps/s: 642.26, examples/s: 657675.15, total examples: 19456000, loss: 2.473531723022461\n",
      "Steps: 19000, time: 1.54, total time: 29.70 seconds, steps/s: 648.09, examples/s: 663641.75, total examples: 20480000, loss: 2.4444687366485596\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "prev_time = time.time()\n",
    "total_examples = 0\n",
    "batch_size = 1024\n",
    "print_size = 1000\n",
    "\n",
    "# gradient descent\n",
    "for k in range(20000):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(Xtr[ix], num_classes=len(stoi)).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    loss = torch.nn.functional.cross_entropy(logits, Ytr[ix])\n",
    "    if (k % print_size == 0):\n",
    "        epoch_time = time.time() - start_time\n",
    "        particular_time = epoch_time - prev_time\n",
    "        prev_time = epoch_time\n",
    "        examples = print_size * batch_size / particular_time\n",
    "        total_examples += print_size * batch_size\n",
    "        print(f\"Steps: {k}, time: {particular_time:.2f}, total time: {epoch_time:.2f} seconds, steps/s: {(print_size / particular_time):.2f}, examples/s: {examples:.2f}, total examples: {total_examples}, loss: {loss.item()}\")\n",
    "\n",
    "    # backward pass\n",
    "    W.grad = None # set to zero the gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -10 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16eb7b8d-0d38-4b48-a891-3a03a5d68413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over training set:  2.4807331562042236\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(Xtr, num_classes=len(stoi)).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "loss = torch.nn.functional.cross_entropy(logits, Ytr)\n",
    "print(\"Loss over training set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d86b765e-0f2c-4990-83bd-70e5b90a4798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss over dev set:  2.4730324745178223\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(Xdev, num_classes=len(stoi)).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "loss = torch.nn.functional.cross_entropy(logits, Ydev)\n",
    "print(\"Loss over dev set: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0f755db3-d77d-4ebd-a817-a605f1246765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "las,\n",
      "pof\n",
      "diveaigulus.\n",
      "oio\n",
      "siacon.\n",
      "Themustticenthundo\n",
      "abe\n",
      "y\n",
      "to\n",
      "singse,68,\n",
      "t\n",
      "25)\n",
      "tses\n",
      "t\n",
      "teralemantthere\n",
      "Ent\n",
      "ptithengrthof\n",
      "op.\n",
      "tof\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "output = []\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=len(stoi)).float()\n",
    "        logits = xenc @ W # predict log-counts\n",
    "        counts = logits.exp() # counts, equivalent to N\n",
    "        p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        if ix != 0:\n",
    "            out.append(itos[ix])\n",
    "        else:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c6b20-1b49-4f45-832b-2eccf8880be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
